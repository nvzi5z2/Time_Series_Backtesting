{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to base (Python 3.11.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec651901-20e0-4f54-ae55-3fd2583e61b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\iFinDPy.pth\n",
      "0\n",
      "登录成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-36812d5ef1d9>:464: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  daily_data[['signal']].fillna(0, inplace=True)\n",
      "<ipython-input-1-36812d5ef1d9>:464: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  daily_data[['signal']].fillna(0, inplace=True)\n",
      "<ipython-input-1-36812d5ef1d9>:464: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  daily_data[['signal']].fillna(0, inplace=True)\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 11 fields in line 379, saw 17\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\量化交易构建\\Time_Serires_Backtesting\\Time_Series_Backtesting\\有效策略库\\组合模型.py:1219\u001b[0m\n\u001b[0;32m   1214\u001b[0m tools\u001b[39m=\u001b[39mTools()\n\u001b[0;32m   1216\u001b[0m \u001b[39m# 生成策略数据\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \n\u001b[0;32m   1218\u001b[0m \u001b[39m#趋势类\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m UDVD_results,_\u001b[39m=\u001b[39m strategies_instance\u001b[39m.\u001b[39mUDVD()\n\u001b[0;32m   1220\u001b[0m V_MACD_results,_ \u001b[39m=\u001b[39m strategies_instance\u001b[39m.\u001b[39mV_MACD()\n\u001b[0;32m   1221\u001b[0m SMA_H_results,_\u001b[39m=\u001b[39mstrategies_instance\u001b[39m.\u001b[39mSMA_H()\n",
      "File \u001b[1;32md:\\量化交易构建\\Time_Serires_Backtesting\\Time_Series_Backtesting\\有效策略库\\组合模型.py:441\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39m# 编写策略主体部分\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39mfor\u001b[39;00m code \u001b[39min\u001b[39;00m target_assets:\n\u001b[0;32m    440\u001b[0m     \u001b[39m# 读取数据\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     daily_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(paths[\u001b[39m'\u001b[39m\u001b[39mdaily\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcode\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m), index_col\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n\u001b[0;32m    442\u001b[0m     daily_data\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(daily_data\u001b[39m.\u001b[39mindex)\n\u001b[0;32m    443\u001b[0m     df\u001b[39m=\u001b[39mdaily_data\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 11 fields in line 379, saw 17\n"
     ]
    }
   ],
   "source": [
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from analyzing_tools import Analyzing_Tools\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from iFinDPy import *\n",
    "\n",
    "def thslogindemo():\n",
    "    # 输入用户的帐号和密码\n",
    "    thsLogin = THS_iFinDLogin(\"hwqh100\",\"155d50\")\n",
    "    print(thsLogin)\n",
    "    if thsLogin != 0:\n",
    "        print('登录失败')\n",
    "    else:\n",
    "        print('登录成功')\n",
    "\n",
    "thslogindemo()\n",
    "\n",
    "\n",
    "# 定义自定义数据类\n",
    "class PandasDataPlusSignal(bt.feeds.PandasData):\n",
    "    lines = ('signal',)\n",
    "    params = (\n",
    "        ('datetime', None),\n",
    "        ('open', 'open'),\n",
    "        ('high', 'high'),\n",
    "        ('low', 'low'),\n",
    "        ('close', 'close'),\n",
    "        ('volume', 'volume'),\n",
    "        ('openinterest', -1),\n",
    "        ('signal', 'signal'),\n",
    "    )\n",
    "\n",
    "\n",
    "class EqualWeightsStrategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('size_pct',0.19),  # 每个资产的仓位百分比\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.orders = {}         # 用于跟踪每个资产的订单状态\n",
    "        self.trade_counts = {}   # 记录每个资产的交易次数\n",
    "        self.value = []          # 存储组合总净值\n",
    "        self.dates = []          # 存储日期序列\n",
    "        self.debug_info = []     # 存储调试信息\n",
    "\n",
    "        for data in self.datas:\n",
    "            name = data._name\n",
    "            self.trade_counts[name] = 0\n",
    "            self.orders[name] = None\n",
    "\n",
    "    def next(self):\n",
    "        total_value = self.broker.getvalue()\n",
    "        self.value.append(total_value)\n",
    "        current_date = self.datas[0].datetime.datetime(0)\n",
    "        self.dates.append(current_date)\n",
    "\n",
    "        # 调试打印\n",
    "        print(f\"Date: {current_date}, Total Value: {total_value}\")\n",
    "\n",
    "        for data in self.datas:\n",
    "            name = data._name\n",
    "            position_size = self.getposition(data).size\n",
    "            signal = data.signal[0]\n",
    "\n",
    "            # 调试打印\n",
    "            print(f\"Asset: {name}, Position Size: {position_size}, Signal: {signal}\")\n",
    "\n",
    "            # 根据信号执行交易\n",
    "            if signal == 1 and position_size == 0:\n",
    "                size = self.calculate_position_size(data)\n",
    "                self.orders[name] = self.buy(data=data, size=size)\n",
    "                self.trade_counts[name] += 1\n",
    "\n",
    "            elif signal == -1 and position_size > 0:\n",
    "                self.orders[name] = self.close(data=data)\n",
    "                self.trade_counts[name] += 1\n",
    "\n",
    "            # 存储调试信息\n",
    "            self.debug_info.append({\n",
    "                'Date': current_date,\n",
    "                'Asset': name,\n",
    "                'Position': position_size,\n",
    "                'Signal': signal,\n",
    "                'Size': self.calculate_position_size(data),\n",
    "                'Open':data.open[0],\n",
    "                'High':data.high[0],\n",
    "                'Low':data.low[0],\n",
    "                'Volume':data.volume[0],\n",
    "                'Close': data.close[0],\n",
    "                'Cash': self.broker.getcash(),\n",
    "                'Value': total_value,\n",
    "                'Trades': self.trade_counts[name],\n",
    "            })\n",
    "\n",
    "    def calculate_position_size(self, data):\n",
    "        \"\"\"\n",
    "        计算仓位大小\n",
    "        \"\"\"\n",
    "        available_cash = self.broker.getvalue()\n",
    "        current_price = data.close[0]\n",
    "        max_investment = available_cash * self.params.size_pct\n",
    "        max_shares = int(max_investment / current_price)\n",
    "        return max_shares\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        \"\"\"\n",
    "        订单完成后重置状态\n",
    "        \"\"\"\n",
    "        if order.status in [order.Completed, order.Canceled, order.Margin]:\n",
    "            name = order.data._name\n",
    "            self.orders[name] = None\n",
    "\n",
    "    def get_net_value_series(self):\n",
    "        \"\"\"\n",
    "        返回净值序列，用于后续分析\n",
    "        \"\"\"\n",
    "        return pd.Series(self.value, index=self.dates, name='Net Value')\n",
    "\n",
    "    def get_debug_df(self):\n",
    "        \"\"\"\n",
    "        返回包含调试信息的DataFrame\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.debug_info)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        return df\n",
    "\n",
    "#定义组合分析工具类，设置策略起始时间\n",
    "class Tools:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.Begin_Date='2019-01-04'\n",
    "\n",
    "        self.current_position={'000300.SH':51823.20,\n",
    "                \"000852.SH\":32038.40,\n",
    "                '000905.SH':31977.60,\n",
    "                \"399006.SZ\":51647.90,\n",
    "                '399303.SZ':31654.00,\n",
    "                'cash':800538.1}\n",
    "\n",
    "        self.ETF_code={'000300.SH':'510310.SH',\n",
    "                \"000852.SH\":\"159845.SZ\",\n",
    "                '000905.SH':\"512500.SH\",\n",
    "                \"399006.SZ\":\"159915.SZ\",\n",
    "                '399303.SZ':\"159628.SZ\"}       \n",
    "        \n",
    "    def Portfolio(self,strategies,initial_cash=10000000):\n",
    "        Begin_Date=self.Begin_Date\n",
    "        # 创建策略名称到资金分配比例的映射\n",
    "        allocation_map = {strat['name']: strat['allocation'] for strat in strategies}\n",
    "\n",
    "        # 初始化结果存储\n",
    "        strategy_returns = {}\n",
    "        strategy_values = {}\n",
    "        strategy_debug_info = {}\n",
    "        initial_cash = initial_cash  # 总初始资金\n",
    "\n",
    "        # 运行每个策略的回测\n",
    "        for strat in strategies:\n",
    "            cerebro = bt.Cerebro()\n",
    "            # 为该策略设置初始资金\n",
    "            strat_cash = initial_cash * strat['allocation']\n",
    "            cerebro.broker.setcash(strat_cash)\n",
    "            # 添加数据到 Cerebro\n",
    "            for code, dataframe in strat['datas'].items():\n",
    "                # 调试打印数据的前几行\n",
    "                print(f\"Adding data for {code} in strategy {strat['name']}:\")\n",
    "                print(dataframe.head())\n",
    "                # 检查必要的列是否存在\n",
    "                required_columns = ['open', 'high', 'low', 'close', 'volume', 'signal']\n",
    "                if not all(col in dataframe.columns for col in required_columns):\n",
    "                    print(f\"Error: Data for {code} is missing required columns.\")\n",
    "                    continue  # 跳过该数据\n",
    "\n",
    "                dataframe = dataframe.sort_index()\n",
    "                select_dataframe=dataframe.loc[Begin_Date:,:]\n",
    "                data_feed = Adding_Signal(dataname=select_dataframe, name=code)\n",
    "                cerebro.adddata(data_feed)\n",
    "            # 添加策略\n",
    "            cerebro.addstrategy(strat['strategy'])\n",
    "            # 运行回测\n",
    "            result = cerebro.run()\n",
    "            # 获取策略实例\n",
    "            strat_instance = result[0]\n",
    "            # 获取净值序列\n",
    "            net_value = strat_instance.get_net_value_series()\n",
    "\n",
    "            # 调试打印\n",
    "            print(f\"Strategy: {strat['name']}, Net Value Series Length: {len(net_value)}\")\n",
    "            print(net_value.head())\n",
    "\n",
    "            # 检查 net_value 是否为空\n",
    "            if net_value.empty:\n",
    "                print(f\"Warning: Strategy {strat['name']} generated an empty net value series.\")\n",
    "\n",
    "            # 存储净值序列\n",
    "            strategy_values[strat['name']] = net_value\n",
    "            # 收集调试信息\n",
    "            debug_df = strat_instance.get_debug_df()\n",
    "            strategy_debug_info[strat['name']] = debug_df\n",
    "\n",
    "        # 合并净值序列，处理不同数据长度问题\n",
    "        # 获取所有日期的并集\n",
    "        all_dates = pd.to_datetime(sorted(set.union(*(set(v.index) for v in strategy_values.values()))))\n",
    "\n",
    "        # 重新索引净值序列，并填充缺失值\n",
    "        for name, net_value in strategy_values.items():\n",
    "            # 去除重复的日期索引\n",
    "            net_value = net_value[~net_value.index.duplicated(keep='first')]\n",
    "            # 重新索引到所有日期\n",
    "            net_value = net_value.reindex(all_dates)\n",
    "            # 填充缺失值，前向填充\n",
    "            net_value = net_value.fillna(method='ffill')\n",
    "            # 填充初始缺失值为初始资金\n",
    "            initial_net_value = initial_cash * allocation_map[name]\n",
    "            net_value = net_value.fillna(initial_net_value)\n",
    "            strategy_values[name] = net_value\n",
    "\n",
    "        # 将净值序列合并为DataFrame\n",
    "        df_values = pd.DataFrame(strategy_values)\n",
    "        # 计算组合净值曲线\n",
    "        df_values['Combined'] = df_values.sum(axis=1)\n",
    "\n",
    "        # 收集所有子策略的调试信息\n",
    "        combined_debug_df = pd.concat(strategy_debug_info.values(), keys=strategy_debug_info.keys())\n",
    "        combined_debug_df = combined_debug_df.reset_index(level=0).rename(columns={'level_0': 'Strategy'})\n",
    "\n",
    "        return df_values,combined_debug_df\n",
    "\n",
    "    def Strategies_Corr_and_NV(self,pf_nv):\n",
    "        \"\"\"\n",
    "        计算基金多个策略的相关性，并绘制热力图。\n",
    "\n",
    "        参数:\n",
    "            pf_nv (pd.DataFrame): 基金策略的净值数据，行是时间，列是策略名称。\n",
    "\n",
    "        返回:\n",
    "            corr_matrix (pd.DataFrame): 策略的相关性矩阵。\n",
    "        \"\"\"\n",
    "        # 计算净值的每日收益率（百分比变化）\n",
    "        pf_nv_pct_change = pf_nv.pct_change().dropna()\n",
    "\n",
    "        # 计算相关性矩阵\n",
    "        corr_matrix = pf_nv_pct_change.corr()\n",
    "\n",
    "        # 设置绘图风格\n",
    "        sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "        # 绘制热力图\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True)\n",
    "        plt.title(\"Strategies Correlation Heatmap\", fontsize=16)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return corr_matrix\n",
    "\n",
    "    def caculate_signals_and_trades(self,debug_df,T0_Date):\n",
    "\n",
    "        current_position=self.current_position\n",
    "        ETF_code=self.ETF_code\n",
    "        T0_debug=debug_df.loc[T0_Date,:]\n",
    "\n",
    "        #先把signal列的信号转换为0方便计算\n",
    "\n",
    "        T0_debug.loc[T0_debug['Signal']==-1,'Signal']=0\n",
    "\n",
    "        #计算应该下单的调整的size\n",
    "\n",
    "        adjusted_signal_and_size=T0_debug[['Asset','Signal','Size','Close']]\n",
    "        adjusted_signal_and_size.loc[:,\"adjusted_size\"]=adjusted_signal_and_size.loc[:,\"Signal\"]*adjusted_signal_and_size.loc[:,\"Size\"]\n",
    "        adjusted_signal_and_size.loc[:,\"trade_amount\"]=adjusted_signal_and_size.loc[:,\"adjusted_size\"]*adjusted_signal_and_size.loc[:,\"Close\"]\n",
    "        Amount_List= adjusted_signal_and_size.groupby(\"Asset\")[\"trade_amount\"].sum().reset_index()\n",
    "\n",
    "        #提取当日总组合的价值\n",
    "\n",
    "        strategy_value=T0_debug.groupby(\"Strategy\")[\"Value\"].sum().reset_index()\n",
    "        number_of_assets= len(T0_debug['Asset'].unique())\n",
    "        strategy_value.loc[:,\"Value\"]=strategy_value.loc[:,\"Value\"]/number_of_assets\n",
    "        portfolio_value_sum=strategy_value.loc[:,\"Value\"].sum()\n",
    "        \n",
    "        #计算占比\n",
    "        pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "        Amount_List.loc[:,\"portfolio_value\"]=portfolio_value_sum\n",
    "        Amount_List=Amount_List.set_index('Asset',drop=True)\n",
    "        cash_trade_amount=portfolio_value_sum-Amount_List.loc[:,\"trade_amount\"].sum()\n",
    "        cash_row = pd.DataFrame({\n",
    "            'trade_amount': [cash_trade_amount],\n",
    "            'portfolio_value': portfolio_value_sum\n",
    "        }, index=['cash'])\n",
    "        Amount_result=pd.concat([Amount_List,cash_row],axis=0)\n",
    "        Amount_result.loc[:,\"proportion\"]=Amount_result.loc[:,\"trade_amount\"]/Amount_result.loc[:,\"portfolio_value\"]\n",
    "        \n",
    "\n",
    "        #和现有持仓进行对比\n",
    "\n",
    "        current_position_df=pd.DataFrame.from_dict(current_position, orient='index', columns=['current_position_value'])\n",
    "        # 计算 current_position_value 的总和\n",
    "        total_value = current_position_df['current_position_value'].sum()\n",
    "\n",
    "        # 添加占比列\n",
    "        current_position_df['current_position_ratio'] = (\n",
    "            current_position_df['current_position_value'] / total_value\n",
    "        )\n",
    "\n",
    "        #合并现有持仓和目标持仓表\n",
    "\n",
    "        result=pd.merge(Amount_result,current_position_df,right_index=True,left_index=True)\n",
    "        result.loc[:,\"adjusted_position\"]=result.loc[:,\"proportion\"]-result.loc[:,\"current_position_ratio\"]\n",
    "        result.loc[:,\"adjusted_value\"]=total_value*result.loc[:,\"adjusted_position\"]\n",
    "\n",
    "\n",
    "        #根据昨日收盘价计算调仓\n",
    "        \n",
    "        index_code=result.index.to_list()\n",
    "        index_code_list=index_code[:-1]\n",
    "        etf_close_price=[]\n",
    "        for code in index_code_list:\n",
    "            etf=ETF_code[code]\n",
    "            close=THS_HQ(etf,'close','',T0_Date,T0_Date).data\n",
    "            close_price=close[\"close\"].values[0]\n",
    "            etf_close_price.append(close_price)\n",
    "        etf_close_price.append(0)\n",
    "        result.loc[:,\"etf_close_price\"]=etf_close_price\n",
    "        result.loc[:,\"adjusted_shares\"]=result.loc[:,\"adjusted_value\"]/result.loc[:,\"etf_close_price\"]\n",
    "        \n",
    "        #和昨日的信号精选对比\n",
    "\n",
    "        T0_Date_datetime=pd.Timestamp(T0_Date)\n",
    "        unique_dates =debug_df.index.unique()\n",
    "        target_index =unique_dates.get_loc(T0_Date_datetime)\n",
    "        if target_index > 0:\n",
    "            previous_date = unique_dates[target_index - 1]\n",
    "\n",
    "        previous_date_df=debug_df.loc[previous_date,:]\n",
    "\n",
    "        #抽取信号信息和表弟信息\n",
    "        previous_date_signal=previous_date_df[['Asset',\"Strategy\",'Signal']]\n",
    "        previous_date_signal=previous_date_signal.reset_index(drop=True)\n",
    "        yesterday_result = previous_date_signal.pivot(index='Asset', columns='Strategy', values='Signal')\n",
    "        \n",
    "        T0_debug_signal=debug_df.loc[T0_Date,:]\n",
    "\n",
    "        T0_debug_signal=T0_debug_signal[['Asset',\"Strategy\",'Signal']]\n",
    "        T0_debug_signal=T0_debug_signal.reset_index(drop=True)\n",
    "        T0_result = T0_debug_signal.pivot(index='Asset', columns='Strategy', values='Signal')\n",
    "        \n",
    "        comparison = T0_result == yesterday_result\n",
    "\n",
    "        if not comparison.values.all():  # 如果存在 False\n",
    "            print(\"信号改变\")\n",
    "        else:\n",
    "            print(\"信号没有改变\")\n",
    "\n",
    "        result=result[['trade_amount','proportion','current_position_ratio','adjusted_position','adjusted_value',\n",
    "                        'etf_close_price','adjusted_shares']]\n",
    "        \n",
    "        return result,comparison\n",
    "    \n",
    "    def set_clusters(self,Corr_df,n_groups):\n",
    "        # 假设 Corr_df 是已经计算好的相关性矩阵\n",
    "        # 转换相关性为距离\n",
    "        distance_matrix = 1 - Corr_df\n",
    "\n",
    "        # 执行层次聚类\n",
    "        linked = linkage(distance_matrix, 'average')\n",
    "\n",
    "        # 绘制树状图来观察聚类情况\n",
    "        dendrogram(linked, labels=Corr_df.index)\n",
    "        plt.title('Dendrogram')\n",
    "        plt.xlabel('Strategy Index')\n",
    "        plt.ylabel('Distance')\n",
    "        # plt.axhline(y=1.4, color='r', linestyle='--')  # 添加一条红线表示截断位置\n",
    "        plt.show()\n",
    "\n",
    "        # # 根据树状图选择的截断值进行聚类\n",
    "        # clusters = fcluster(linked, 1.4, criterion='distance')\n",
    "\n",
    "        # 直接指定生成三个聚类\n",
    "        clusters = fcluster(linked, n_groups, criterion='maxclust')\n",
    "\n",
    "        # 将聚类结果添加到原始 DataFrame 中\n",
    "        Corr_df['Cluster'] = clusters\n",
    "\n",
    "        # 输出聚类结果\n",
    "        print(Corr_df['Cluster'])\n",
    "\n",
    "        # 创建一个字典来存储每个聚类的成员列表\n",
    "        cluster_dict = {}\n",
    "        for cluster_id in np.unique(clusters):\n",
    "            cluster_dict[cluster_id] = list(Corr_df.index[Corr_df['Cluster'] == cluster_id])\n",
    "\n",
    "        # 输出每个聚类的成员\n",
    "        for key, value in cluster_dict.items():\n",
    "            print(f\"Cluster {key}: {value}\")\n",
    "\n",
    "        return cluster_dict\n",
    "\n",
    "\n",
    "# 定义策略类（设置数据路径和选择资产）\n",
    "class Strategies:\n",
    "\n",
    "    def __init__(self):\n",
    "        # 定义数据路径\n",
    "        self.paths = {\n",
    "            'daily': r'D:\\数据库\\同花顺ETF跟踪指数量价数据\\1d',\n",
    "            'hourly': r'D:\\数据库\\同花顺ETF跟踪指数量价数据\\1h',\n",
    "            'min15': r'D:\\数据库\\同花顺ETF跟踪指数量价数据\\15min',\n",
    "            'option': r'D:\\数据库\\另类数据\\ETF期权数据',\n",
    "            'EDB':r'D:\\数据库\\同花顺EDB数据',\n",
    "            'new_HL': r'D:\\数据库\\另类数据\\新高新低\\001005010.csv',\n",
    "            'up_companies':r'D:\\数据库\\另类数据\\涨跌家数\\A股.csv',\n",
    "            'up_down': r'D:\\数据库\\另类数据\\涨停跌停\\001005010.csv',\n",
    "            'A50': r'D:\\数据库\\另类数据\\A50数据\\CN0Y.SG.csv',\n",
    "            #'pv_export':r\"D:\\量化交易构建\\私募基金研究\\股票策略研究\\策略净值序列\"\n",
    "        }\n",
    "        # 定义选择的资产\n",
    "        self.target_assets = [\"000300.SH\",\"000852.SH\",\n",
    "                              \"000905.SH\", \"399006.SZ\",\"399303.SZ\"]\n",
    "\n",
    "    # 突破类策略\n",
    "    def UDVD(self,window_1=27):\n",
    "        # 信号结果字典\n",
    "        results = {}\n",
    "        # 全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "\n",
    "        paths=self.paths\n",
    "\n",
    "        # 编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            df=daily_data.copy()\n",
    "            close = df[\"close\"]\n",
    "            open = df['open']    \n",
    "            low = df[\"low\"]\n",
    "            high = df[\"high\"]\n",
    "            volume = df['volume']\n",
    "            # 计算\n",
    "            volup = (high-open)/open\n",
    "            voldown = (open-low)/open\n",
    "            ud= volup - voldown\n",
    "\n",
    "            df[\"var_1\"] = ud.rolling(window_1).mean()\n",
    "            df[\"var_2\"] =0\n",
    "            # 添加信号列\n",
    "            df.loc[(df[\"var_1\"].shift(1) <= df[\"var_2\"].shift(1)) & (df[\"var_1\"] >= df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) > df[\"var_2\"].shift(1)) & (df[\"var_1\"] < df[\"var_2\"]) , 'signal'] = -1\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "            result=df\n",
    "\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    #均线类策略\n",
    "    def Alligator_strategy_with_Ao_and_Fractal_Macd(self):\n",
    "        # 信号结果字典\n",
    "        results = {}\n",
    "        # 全数据字典，包含计算指标用于检查\n",
    "        full_info = {}\n",
    "\n",
    "        paths=self.paths\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            hourly_data = pd.read_csv(os.path.join(paths['hourly'], f\"{code}.csv\"), index_col=[0])\n",
    "            hourly_data.index = pd.to_datetime(hourly_data.index)\n",
    "            mins_15_data = pd.read_csv(os.path.join(paths['min15'], f\"{code}.csv\"), index_col=[0])\n",
    "            mins_15_data.index = pd.to_datetime(mins_15_data.index)\n",
    "            mins_15_data = mins_15_data[~mins_15_data.index.duplicated(keep='first')]\n",
    "\n",
    "            # 提取收盘价\n",
    "            daily_data_close = daily_data[['close']]\n",
    "            daily_data_high = daily_data[['high']]\n",
    "            daily_data_low = daily_data[['low']]\n",
    "            hourly_data_close = hourly_data[['close']]\n",
    "            mins_15_data_close = mins_15_data[['close']]\n",
    "\n",
    "            # 确保数据为数值类型\n",
    "            daily_data_high = pd.to_numeric(daily_data_high.squeeze(), errors='coerce')\n",
    "            daily_data_low = pd.to_numeric(daily_data_low.squeeze(), errors='coerce')\n",
    "\n",
    "            # 计算鳄鱼线指标\n",
    "            Jaw = daily_data_close.rolling(window=13).mean().shift(8)\n",
    "            Jaw.columns=['Jaw']\n",
    "            Teeth = hourly_data_close.rolling(window=8).mean().shift(5)\n",
    "            Teeth.columns=['Teeth']\n",
    "            Lips = mins_15_data_close.rolling(window=5).mean().shift(3)\n",
    "            Lips.columns=['Lips']\n",
    "\n",
    "            # 合并鳄鱼线数据并统一到日频\n",
    "            combined = pd.concat([daily_data, Jaw, Teeth, Lips], axis=1)\n",
    "            combined.fillna(method='ffill', inplace=True)\n",
    "            result = combined.resample('D').last()\n",
    "            result.dropna(inplace=True)\n",
    "\n",
    "            # 生成交易信号\n",
    "            def signal_generation(row):\n",
    "                if row['Lips'] > row['Teeth'] > row['Jaw']:\n",
    "                    return 1  # 多头信号\n",
    "                elif row['Lips'] < row['Teeth'] < row['Jaw']:\n",
    "                    return -1  # 空头信号\n",
    "                else:\n",
    "                    return 0  # 无信号\n",
    "\n",
    "            result['Alligator_signal'] = result.apply(signal_generation, axis=1)\n",
    "\n",
    "            #分形形态信号计算\n",
    "            def identify_fractals_and_record_values(df):\n",
    "                \"\"\"\n",
    "                识别分形并记录过去 5 日的最高价的最高值和最低价的最低值。\n",
    "                :param data: 包含时间序列数据的 DataFrame，需包含 'high', 'low', 'close' 列。\n",
    "                :return: 包含 up_fractal_value 和 down_fractal_value 的 DataFrame。\n",
    "                \"\"\"\n",
    "                # 初始化两列用于记录分形值\n",
    "                data=df.copy()\n",
    "                data['up_fractal_value'] = None\n",
    "                data['down_fractal_value'] = None\n",
    "\n",
    "                # 遍历数据，识别分形并记录关键值\n",
    "                for i in range(4, len(data) - 4):  # 确保有足够的数据进行完整分形判断\n",
    "                    # 向上分形：中间高点最高，且左右两侧逐级降低\n",
    "                    if (data['high'][i] > data['high'][i - 1] and data['high'][i] > data['high'][i + 1] and  # 中间点高于左右\n",
    "                        data['high'][i - 1] > data['high'][i - 2] and data['high'][i + 1] > data['high'][i + 2] and  # 左右点高于更远点\n",
    "                        data['high'][i - 2] > data['high'][i - 3] and data['high'][i + 2] > data['high'][i + 3]):  # 更远点高于最远点\n",
    "                        # 记录过去 5 日的最高价的最高值\n",
    "                        data.loc[data.index[i], 'up_fractal_value'] = data['high'][i - 4:i + 1].max()\n",
    "\n",
    "                    # 向下分形：中间低点最低，且左右两侧逐级升高\n",
    "                    if (data['low'][i] < data['low'][i - 1] and data['low'][i] < data['low'][i + 1] and  # 中间点低于左右\n",
    "                        data['low'][i - 1] < data['low'][i - 2] and data['low'][i + 1] < data['low'][i + 2] and  # 左右点低于更远点\n",
    "                        data['low'][i - 2] < data['low'][i - 3] and data['low'][i + 2] < data['low'][i + 3]):  # 更远点低于最远点\n",
    "                        # 记录过去 5 日的最低价的最低值\n",
    "                        data.loc[data.index[i], 'down_fractal_value'] = data['low'][i - 4:i + 1].min()\n",
    "\n",
    "                # 向下填充分形值\n",
    "                data['up_fractal_value'].fillna(method='ffill', inplace=True)\n",
    "                data['down_fractal_value'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "                return data\n",
    "            \n",
    "            def calculate_fractal_signals(df):\n",
    "                \"\"\"\n",
    "                基于分形值计算交易信号，并在特定情况下保持上一周期的信号。\n",
    "                :param data: 包含 'close', 'up_fractal_value', 'down_fractal_value' 列的 DataFrame。\n",
    "                :return: 包含 fractal_signal 的 DataFrame。\n",
    "                \"\"\"\n",
    "                # 初始化信号列，默认值为 0\n",
    "                data=df.copy()\n",
    "                data['fractal_signal'] = 0\n",
    "\n",
    "                # 遍历数据，每一行根据条件更新信号\n",
    "                for i in range(1, len(data)):\n",
    "                    if data['close'][i] > data['up_fractal_value'][i]:  # 收盘价高于最近的上分形的最高价，看多\n",
    "                        data.loc[data.index[i], 'fractal_signal'] = 1\n",
    "                    elif data['close'][i] < data['down_fractal_value'][i]:  # 收盘价低于最近的下分形的最低价，看空\n",
    "                        data.loc[data.index[i], 'fractal_signal'] = -1\n",
    "                    else:  # 其他情况，维持上一周期的信号\n",
    "                        data.loc[data.index[i], 'fractal_signal'] = 0\n",
    "\n",
    "                return data\n",
    "    \n",
    "            fractals_data= identify_fractals_and_record_values(daily_data)\n",
    "            fractals_signals = calculate_fractal_signals(fractals_data)\n",
    "            result['Fractal_signal'] = fractals_signals['fractal_signal']\n",
    "\n",
    "            # 计算 AO 指标\n",
    "            median_price = (daily_data_high + daily_data_low) / 2\n",
    "            ao_short = median_price.rolling(window=5).mean()\n",
    "            ao_long = median_price.rolling(window=34).mean()\n",
    "            AO = ao_short - ao_long\n",
    "\n",
    "            # 将 AO 转化为 DataFrame，并与鳄鱼线数据对齐\n",
    "            ao_df = AO.to_frame(name='AO').dropna()  # 将 AO 转换为 DataFrame\n",
    "\n",
    "            # 计算 AO 的变化方向\n",
    "            ao_df['AO_Diff'] = ao_df['AO'].diff()\n",
    "\n",
    "            # 判断连续上涨和下跌天数\n",
    "            ao_df['Up_Count'] = (ao_df['AO_Diff'] > 0).astype(int).rolling(window=3).sum()\n",
    "            ao_df['Down_Count'] = (ao_df['AO_Diff'] < 0).astype(int).rolling(window=3).sum()\n",
    "\n",
    "            # 根据规则生成信号\n",
    "            ao_df['AO_signal'] = np.where(ao_df['Up_Count'] == 3, 1, \n",
    "                                        np.where(ao_df['Down_Count'] == 3, -1, np.nan))\n",
    "\n",
    "            # 延续上一个信号\n",
    "            ao_df['AO_signal'] = ao_df['AO_signal'].fillna(0)\n",
    "\n",
    "            # 删除辅助列，保留 AO 和 AO_signal\n",
    "            ao_df = ao_df[['AO_signal']]\n",
    "\n",
    "            result=pd.merge(result,ao_df,right_index=True,left_index=True)\n",
    "\n",
    "            #计算MACD指标\n",
    "            df = daily_data.copy()\n",
    "            # 1. 计算快线（DIFF）和慢线（DEA）\n",
    "            df['ema_short'] = df['close'].ewm(span=12, adjust=False).mean()\n",
    "            df['ema_long'] = df['close'].ewm(span=26, adjust=False).mean()\n",
    "            df['diff'] = df['ema_short'] - df['ema_long']  # DIFF 快线\n",
    "            df['dea'] = df['diff'].ewm(span=9, adjust=False).mean()  # DEA 慢线\n",
    "            \n",
    "            # 2. 计算能量柱\n",
    "            df['macd_bar'] = (df['diff'] - df['dea']) * 2\n",
    "\n",
    "            # 添加macd信号列\n",
    "            def macd_generate_signal(row):\n",
    "                # 水上或零轴看多信号\n",
    "                if row['diff'] > row['dea'] and row['macd_bar'] >= 0:\n",
    "                    return 1\n",
    "                # 水下或零轴看空信号\n",
    "                elif row['diff'] < row['dea'] and row['macd_bar'] <= 0:\n",
    "                    return -1\n",
    "                # 无信号\n",
    "                else:\n",
    "                    return 0\n",
    "\n",
    "            # 应用macd信号生成规则\n",
    "            df['MACD_signal'] = df.apply(macd_generate_signal, axis=1)\n",
    "            \n",
    "            macd_df=df[['MACD_signal']]\n",
    "\n",
    "            result=pd.merge(result,macd_df,right_index=True,left_index=True)\n",
    "            #计算最终信号\n",
    "\n",
    "            result['signal'] = 0\n",
    "            for i in range(len(result)):\n",
    "                long_condition = (result['Alligator_signal'][i] == 1 and \n",
    "                                (result['MACD_signal'][i] == 1 or result['Fractal_signal'][i] == 1\n",
    "                                or result['AO_signal'][i] == 1)\n",
    "                                )\n",
    "                short_condition = (result['Alligator_signal'][i] == -1 or\n",
    "                                result['AO_signal'][i] == -1 or result['Fractal_signal'][i] == -1 or\n",
    "                                result['MACD_signal'][i]== -1)\n",
    "                \n",
    "                if long_condition and short_condition:  # 同时触发多空信号\n",
    "                    result['signal'][i] = result['signal'][i - 1] if i > 0 else 0  # 延续上一周期信号\n",
    "                elif long_condition:\n",
    "                    result['signal'][i] = 1  # 看多\n",
    "                elif short_condition:\n",
    "                    result['signal'][i] = -1  # 看空\n",
    "                else:\n",
    "                    result['signal'][i] = result['signal'][i - 1] if i > 0 else 0 # 延续上一周期信号\n",
    "\n",
    "            # 存储结果\n",
    "            signal=result[['signal']]\n",
    "            results[code]=pd.merge(daily_data,signal,right_index=True,left_index=True)\n",
    "            full_info[code] = result  # 包含所有信号计算信息的数据\n",
    "\n",
    "        return results, full_info\n",
    "\n",
    "        # 自定义数据类，包含 'signal'\n",
    "        class PandasDataPlusSignal(bt.feeds.PandasData):\n",
    "            lines = ('signal',)\n",
    "            params = (\n",
    "                ('signal', -1),  # 默认情况下，'signal' 列在最后一列   \n",
    "            )\n",
    "\n",
    "    def SMA_H(self,window_1=61,window_2=101):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        \n",
    "        paths=self.paths\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "\n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            df=daily_data.copy()\n",
    "            hourly_data = pd.read_csv(os.path.join(paths['hourly'], f\"{code}.csv\"), index_col=[0])\n",
    "            hourly_data.index = pd.to_datetime(hourly_data.index)\n",
    "\n",
    "            hourly_data[\"var_1\"] = hourly_data['close'].rolling(window_1).mean()\n",
    "            hourly_data[\"var_2\"] =hourly_data['close'].rolling(window_2).mean()\n",
    "            # 添加信号列\n",
    "            hourly_data.loc[(hourly_data[\"var_1\"].shift(1) <= hourly_data[\"var_2\"].shift(1)) & (hourly_data[\"var_1\"] >= hourly_data[\"var_2\"]) , 'signal'] = 1\n",
    "            hourly_data.loc[(hourly_data[\"var_1\"].shift(1) > hourly_data[\"var_2\"].shift(1)) & (hourly_data[\"var_1\"] < hourly_data[\"var_2\"]) , 'signal'] = -1\n",
    "            \n",
    "            hourly_data['signal'].fillna(method='ffill', inplace=True)\n",
    "            hourly_exchange = hourly_data.resample('D').last()\n",
    "\n",
    "            df = pd.merge(df, hourly_exchange[['signal']], left_index=True, right_index=True, how='left')        \n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "            result=df\n",
    "\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    # 成交量类策略\n",
    "    def V_MACD(self,window_1=42,window_2=0):\n",
    "        # 信号结果字典\n",
    "        results = {}\n",
    "        # 全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "\n",
    "        paths=self.paths\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "        \n",
    "        # 编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "\n",
    "            volume = df['volume']\n",
    "            df['EMA_F'] =volume.ewm(12).mean()\n",
    "            df['EMA_S'] = volume.ewm(26).mean()\n",
    "            df['V_DIF'] = df['EMA_F'] - df['EMA_S']\n",
    "            df['V_DEA'] = df['V_DIF'].ewm(9).mean()\n",
    "            df['VMACD']=(df['V_DIF']-df['V_DEA'])*2\n",
    "\n",
    "            # 标准化处理\n",
    "            df['VMACD_mean'] = df['VMACD'].rolling(window_1).mean()\n",
    "            df['VMACD_std'] = df['VMACD'].rolling(window_1).std()\n",
    "            df['Z_VMACD'] = (df['VMACD'] - df['VMACD_mean']) / df['VMACD_std']\n",
    "            df['VMACD_MTM'] = df['Z_VMACD'].rolling(window_1).sum()\n",
    "\n",
    "            # 计算\n",
    "            df[\"var_1\"] = df['VMACD_MTM']\n",
    "            df[\"var_2\"] = window_2/10\n",
    "            df[\"var_3\"] = -window_2/10\n",
    "\n",
    "            # 信号触发条件\n",
    "            df.loc[(df[\"var_1\"].shift(1) <= df[\"var_2\"].shift(1)) & (df[\"var_1\"] > df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) > df[\"var_3\"].shift(1)) & (df[\"var_1\"] <= df[\"var_3\"]), 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    #期权类策略\n",
    "    def PCR(self,window_1=62):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "            option_code='510050'\n",
    "            data = pd.read_csv(os.path.join(paths['option'], f\"{option_code}.csv\"), index_col=[0])\n",
    "            data.index= pd.to_datetime(data.index)\n",
    "            \n",
    "            #和指数数据合并\n",
    "            merged_df = pd.merge(df, data[['p02872_f005', 'p02872_f006']], left_index=True, right_index=True, how='left')        \n",
    "            #计算PCR滚动五天的均值\n",
    "            merged_df['PCR']= merged_df['p02872_f006'].rolling(5).mean()/merged_df['p02872_f005'].rolling(5).mean()\n",
    "            # 定义一个函数来计算从小到大排列后排名第 70% 的值\n",
    "            def calc_70th_percentile(x):\n",
    "                return np.percentile(x, 70)\n",
    "\n",
    "            # 使用 rolling 方法计算过去六十日从小到大排列后第 70 个百分位数\n",
    "            merged_df['rolloing_70%'] = merged_df['PCR'].rolling(window_1).apply(calc_70th_percentile, raw=True)\n",
    "\n",
    "            df['PCR'] = merged_df['PCR']\n",
    "            df['rolloing_70%'] = merged_df['rolloing_70%']\n",
    "\n",
    "\n",
    "            # 信号触发条件\n",
    "            df.loc[(df[\"PCR\"].shift(1) <= df[\"rolloing_70%\"].shift(1)) & (df[\"PCR\"] > df[\"rolloing_70%\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"PCR\"].shift(1) > df[\"rolloing_70%\"].shift(1)) & (df[\"PCR\"] <= df[\"rolloing_70%\"]), 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    #宏观类策略\n",
    "\n",
    "    def Inventory_Cycle(self,window_1=7):\n",
    "        #PMI：原材料库存代码=M002043811\n",
    "        #BCI:企业库存前瞻指数=M004488064 \n",
    "\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        \n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据量价数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            df=daily_data.copy()\n",
    "\n",
    "            #读取EDB数据\n",
    "            PMI_Inventory= pd.read_csv(paths['EDB']+'\\\\'+'M002043811.csv')\n",
    "            PMI_Inventory=PMI_Inventory.set_index('time',drop=True)\n",
    "            PMI_Inventory_value=PMI_Inventory[['value']]\n",
    "            PMI_Inventory_value.columns=['PMI_Inventory_Index']\n",
    "            PMI_Inventory_value=PMI_Inventory_value.sort_index()\n",
    "            #计算第一个信号（PMI原材料库存信号）\n",
    "\n",
    "            def process_macro_data_rolling(data, column_name, window=36):\n",
    "                \"\"\"\n",
    "                对输入的宏观数据进行滚动极端值处理和Zscore标准化处理（基于滚动窗口）。\n",
    "\n",
    "                参数：\n",
    "                data : pd.DataFrame\n",
    "                    包含待处理数据的DataFrame。\n",
    "                column_name : str\n",
    "                    需要处理的列名。\n",
    "                window : int\n",
    "                    滚动窗口的大小（默认为36列）。\n",
    "                \n",
    "                返回：\n",
    "                pd.DataFrame\n",
    "                    包含处理后数据的DataFrame，新增列为 {column_name}_Zscore。\n",
    "                \"\"\"\n",
    "                # 确保列存在\n",
    "                if column_name not in data.columns:\n",
    "                    raise ValueError(f\"列名 {column_name} 不存在于输入数据中\")\n",
    "\n",
    "                # 初始化新列\n",
    "                zscore_column_name = f\"{column_name}_Zscore\"\n",
    "                data[zscore_column_name] = np.nan\n",
    "\n",
    "                # 滚动窗口计算\n",
    "                for i in range(window - 1, len(data)):\n",
    "                    # 提取过去window列的数据\n",
    "                    rolling_window = data[column_name].iloc[i - window + 1:i + 1]\n",
    "\n",
    "                    # 计算滚动均值和标准差\n",
    "                    mean = rolling_window.mean()\n",
    "                    std = rolling_window.std()\n",
    "\n",
    "                    # 定义上下限\n",
    "                    upper_limit = mean + 3 * std\n",
    "                    lower_limit = mean - 3 * std\n",
    "\n",
    "                    # 当前值进行极端值处理\n",
    "                    current_value = data[column_name].iloc[i]\n",
    "                    clipped_value = np.clip(current_value, lower_limit, upper_limit)\n",
    "\n",
    "                    # 计算Zscore并赋值\n",
    "                    data.loc[data.index[i], zscore_column_name] = (clipped_value - mean) / std\n",
    "                    data.dropna()\n",
    "\n",
    "                return data[['PMI_Inventory_Index_Zscore']]\n",
    "            \n",
    "            PMI_Inventory_Index_Zscore=process_macro_data_rolling(PMI_Inventory_value,'PMI_Inventory_Index')\n",
    "            #输出PMI的信号\n",
    "            multiplier=window_1/10\n",
    "        \n",
    "            def generate_signals_with_cleaning(data, column_name, window=36, multiplier=0.8):\n",
    "                \"\"\"\n",
    "                根据Zscore生成信号，并删除前36个月的数据以避免回测时出错\n",
    "\n",
    "                参数：\n",
    "                data : pd.DataFrame\n",
    "                    包含处理后数据的DataFrame\n",
    "                column_name : str\n",
    "                    需要处理的列名（Zscore列）\n",
    "                window : int, 可选\n",
    "                    滚动窗口大小，默认为36个月\n",
    "                multiplier : float, 可选\n",
    "                    标准差的倍数，默认为0.8\n",
    "\n",
    "                返回：\n",
    "                pd.DataFrame\n",
    "                    包含信号的DataFrame，删除了前36个月的数据\n",
    "                \"\"\"\n",
    "                if column_name not in data.columns:\n",
    "                    raise ValueError(f\"列名 {column_name} 不存在于输入数据中\")\n",
    "\n",
    "                # 计算滚动标准差\n",
    "                rolling_std = data[column_name].rolling(window=window).std()\n",
    "\n",
    "                # 计算正负0.8倍标准差\n",
    "                upper_bound = multiplier * rolling_std\n",
    "                lower_bound = -multiplier * rolling_std\n",
    "\n",
    "                # 初始化信号\n",
    "                signals = []\n",
    "\n",
    "                # 生成信号\n",
    "                for i in range(len(data)):\n",
    "                    if i < window:  # 在滚动窗口大小之前，无数据可用\n",
    "                        signals.append(np.nan)\n",
    "                    else:\n",
    "                        if data[column_name].iloc[i] > upper_bound.iloc[i]:\n",
    "                            signals.append(-1)  # 看空信号\n",
    "                        elif data[column_name].iloc[i] < lower_bound.iloc[i]:\n",
    "                            signals.append(1)  # 看多信号\n",
    "                        else:\n",
    "                            signals.append(signals[-1])  # 维持上一个信号\n",
    "\n",
    "                # 将信号加入数据框\n",
    "                data['Signal'] = signals\n",
    "\n",
    "                # 删除前36个月的数据（滚动窗口前的数据）\n",
    "                data = data.iloc[window:].copy()\n",
    "\n",
    "                return data[['Signal']]\n",
    "                    \n",
    "            PMI_Signals = generate_signals_with_cleaning(PMI_Inventory_Index_Zscore, 'PMI_Inventory_Index_Zscore',multiplier=multiplier)\n",
    "\n",
    "            PMI_Signals.columns=['signal']\n",
    "\n",
    "            PMI_Signals.index=pd.to_datetime(PMI_Signals.index)\n",
    "\n",
    "            # 使用 resample 将月频转换为日频\n",
    "            PMI_Signals_daily = PMI_Signals.resample('D').ffill()\n",
    "            PMI_Signals_daily.index=pd.to_datetime(PMI_Signals_daily.index)\n",
    "            \n",
    "            #存储结果\n",
    "            total_info=pd.concat([daily_data,PMI_Signals_daily],axis=1)\n",
    "            first_signal_date=PMI_Signals_daily.index[0]\n",
    "            first_signal_formatted_date=first_signal_date.strftime('%Y-%m-%d')\n",
    "            total_info_selected=total_info.loc[first_signal_formatted_date:,:]\n",
    "\n",
    "            #填充缺失值\n",
    "            total_info_selected=total_info_selected.ffill()\n",
    "\n",
    "            signal=total_info_selected[['signal']]\n",
    "\n",
    "            daily_data.loc[:,\"signal\"]=signal\n",
    "\n",
    "            results[code] = daily_data.dropna()\n",
    "\n",
    "            full_info[code]=daily_data    \n",
    "        \n",
    "        return results,full_info\n",
    "\n",
    "    #情绪类\n",
    "\n",
    "    def high_low(self,window_1=12):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        \n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "\n",
    "            #将上涨、平、下跌数量和涨跌停数量合并\n",
    "            high_low_path=paths['new_HL']\n",
    "            high_low=pd.read_csv(high_low_path)\n",
    "            up_company_path=paths['up_companies']\n",
    "            data = pd.read_csv(up_company_path)\n",
    "            data=data.rename(columns={'p00112_f001':'time'})\n",
    "            high_low['time'] = pd.to_datetime(high_low['time'])\n",
    "            data['time'] = pd.to_datetime(data['time'])\n",
    "            num_df = pd.merge(high_low, data[['p00112_f002', 'p00112_f003', 'p00112_f004', 'time']], on='time', how='left')        \n",
    "            num_df.set_index('time', inplace=True)\n",
    "\n",
    "            #和指数数据合并\n",
    "            merged_df = pd.merge(df, num_df[['ths_new_high_num_block','ths_new_low_num_block','p00112_f002', 'p00112_f003', 'p00112_f004']], left_index=True, right_index=True, how='left')        \n",
    "            \n",
    "            #计算涨跌停剪刀差\n",
    "            merged_df['股票数量']=merged_df['p00112_f002'] +  merged_df['p00112_f003'] + merged_df['p00112_f004']\n",
    "            merged_df['新高数量']=merged_df['ths_new_high_num_block']\n",
    "            merged_df['新低数量']=merged_df['ths_new_low_num_block']\n",
    "            merged_df['高低差']=(merged_df['新高数量']-merged_df['新低数量'])/merged_df['股票数量']\n",
    "            merged_df['高低差'].fillna(method='ffill', inplace=True)\n",
    "            # 确保merged_df的索引唯一\n",
    "            merged_df = merged_df[~merged_df.index.duplicated(keep='first')]\n",
    "\n",
    "            df['var_1'] = merged_df['高低差']\n",
    "            df['var_2'] = -0.2\n",
    "            df['var_3']=window_1/1000\n",
    "            # 根据条件生成信号值列\n",
    "            df.loc[(df[\"var_1\"].shift(1) >= df[\"var_2\"].shift(1)) & (df[\"var_1\"] < df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) < df[\"var_3\"].shift(1)) & (df[\"var_1\"] >= df[\"var_3\"]) , 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "\n",
    "    def UD(self,window_1=38,window_2=65):\n",
    "            #信号结果字典\n",
    "            results = {}\n",
    "            #全数据字典，包含计算指标用于检查\n",
    "            full_info={}\n",
    "            target_assets=self.target_assets\n",
    "            paths=self.paths\n",
    "            \n",
    "            #编写策略主体部分\n",
    "            for code in target_assets:\n",
    "                # 读取数据\n",
    "                daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "                daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "                df=daily_data.copy()\n",
    "\n",
    "                #将上涨、平、下跌数量和涨跌停数量合并\n",
    "                up_down_path=paths['up_down']\n",
    "                up_down=pd.read_csv(up_down_path)\n",
    "                up_company_path=paths['up_companies']\n",
    "                data = pd.read_csv(up_company_path)\n",
    "                data=data.rename(columns={'p00112_f001':'time'})\n",
    "                up_down['time'] = pd.to_datetime(up_down['time'])\n",
    "                data['time'] = pd.to_datetime(data['time'])\n",
    "                num_df = pd.merge(up_down, data[['p00112_f002', 'p00112_f003', 'p00112_f004', 'time']], on='time', how='left')        \n",
    "                num_df.set_index('time', inplace=True)\n",
    "\n",
    "                #和指数数据合并\n",
    "                merged_df = pd.merge(df, num_df[['ths_limit_up_stock_num_sector','ths_limit_down_stock_num_sector','p00112_f002', 'p00112_f003', 'p00112_f004']], left_index=True, right_index=True, how='left')        \n",
    "                \n",
    "                #计算涨跌停剪刀差\n",
    "                merged_df['股票数量']=merged_df['p00112_f002'] +  merged_df['p00112_f003'] + merged_df['p00112_f004']\n",
    "                merged_df['涨停数量']=merged_df['ths_limit_up_stock_num_sector']\n",
    "                merged_df['跌停数量']=merged_df['ths_limit_down_stock_num_sector']\n",
    "                merged_df['涨跌停差']=(merged_df['涨停数量']-merged_df['跌停数量'])/merged_df['股票数量']\n",
    "\n",
    "                # 计算AMA\n",
    "                merged_df['AMA_30'] = merged_df['涨跌停差'].ewm(window_1).mean()\n",
    "                merged_df['AMA_100'] = merged_df['涨跌停差'].ewm(window_2).mean()\n",
    "                merged_df['AMA']=merged_df['AMA_30']/merged_df['AMA_100']\n",
    "\n",
    "\n",
    "                merged_df['ration']=merged_df['AMA']\n",
    "                # 确保merged_df的索引唯一\n",
    "                merged_df = merged_df[~merged_df.index.duplicated(keep='first')]\n",
    "\n",
    "                df['var_1'] = merged_df['ration']\n",
    "                df['var_2'] = 1.15\n",
    "                df['var_3']=merged_df['AMA_30']\n",
    "                df['var_4']=merged_df['AMA_100']\n",
    "\n",
    "                # 根据条件生成信号值列\n",
    "                df['signal_1'] = -1  # 初始化信号列为 -1\n",
    "                condition = (df['var_1'] > df['var_2']) & (df['var_3'] > 0) & (df['var_4'] > 0)\n",
    "                df.loc[condition, 'signal_1'] = 1\n",
    "                \n",
    "                df['var_5'] = merged_df['涨跌停差']\n",
    "                df['var_6'] = -0.2\n",
    "                df['var_7']=0.019\n",
    "                # 根据条件生成信号值列\n",
    "                df.loc[(df[\"var_5\"].shift(1) >= df[\"var_6\"].shift(1)) & (df[\"var_5\"] < df[\"var_6\"]) , 'signal_2'] = 1\n",
    "                df.loc[(df[\"var_5\"].shift(1) < df[\"var_7\"].shift(1)) & (df[\"var_5\"] >= df[\"var_7\"]) , 'signal_2'] = -1\n",
    "                # pos为空的，向上填充数字\n",
    "                df['signal_2'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "                df['signal_sum']=df['signal_1']+df['signal_2']\n",
    "                # 添加signal列，使用apply函数\n",
    "                df['signal'] = df['signal_sum'].apply(lambda x: 1 if x >= 0 else -1)\n",
    "                result=df\n",
    "                # 将信号合并回每日数据\n",
    "                daily_data = daily_data.join(result[['signal']], how='left')\n",
    "                daily_data[['signal']].fillna(0, inplace=True)\n",
    "                daily_data=daily_data.dropna()\n",
    "\n",
    "                # 存储结果\n",
    "                results[code] = daily_data\n",
    "                full_info[code]=result\n",
    "\n",
    "            return results,full_info\n",
    "\n",
    "    #外资类\n",
    "    \n",
    "    def FS_A50(self,window_1=20):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        \n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "            df = df.round(0)\n",
    "            # 使用需要的列，通常是高、低、收盘价\n",
    "            close = df[\"close\"]    \n",
    "            low = df[\"low\"]\n",
    "            open= df['open']\n",
    "            high = df[\"high\"]\n",
    "            volume = df['volume']\n",
    "\n",
    "            #导入富时A50\n",
    "            A50_Path=paths['A50']\n",
    "            data = pd.read_csv(A50_Path)\n",
    "            #导入中证全指\n",
    "            zzqz=pd.read_csv(os.path.join(paths['daily'], f\"{'000985.CSI'}.csv\"))\n",
    "            #日期\n",
    "            data['time'] = pd.to_datetime(data['time'])\n",
    "            zzqz['time'] = pd.to_datetime(zzqz['time'])\n",
    "            #self.df['time'] = pd.to_datetime(self.df['time'])\n",
    "            #按照时间升序排列\n",
    "            data= data.sort_values(by='time')\n",
    "            zzqz= zzqz.sort_values(by='time')\n",
    "            #计算涨跌幅\n",
    "            data['chg']=(data['ths_close_price_future']-data['ths_open_price_future'])/data['ths_open_price_future']\n",
    "            merged_df = pd.merge(zzqz, data[['time', 'chg']], left_on='time', right_on='time', how='left')\n",
    "            # 向下填充'value'列的NaN值\n",
    "            merged_df['chg'].fillna(method='ffill', inplace=True)\n",
    "            #计算富时A50及中证全指差值\n",
    "            merged_df['diff']=merged_df['chg']-(merged_df['close']-merged_df['open'])/merged_df['open']\n",
    "            #将中证全债及富时A50的差合并到df中\n",
    "            merged_df.set_index('time', inplace=True)   \n",
    "\n",
    "            df = pd.merge(df, merged_df[['diff']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "\n",
    "            df['var_1'] = df['diff']\n",
    "            df['var_2'] = window_1/1000\n",
    "            \n",
    "            df.loc[(df[\"var_1\"].shift(1) <= df[\"var_2\"].shift(1)) & (df[\"var_1\"] > df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) > df[\"var_2\"].shift(1)) & (df[\"var_1\"] <= df[\"var_2\"]) , 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "\n",
    "\n",
    "# 实例化策略类\n",
    "strategies_instance = Strategies()\n",
    "tools=Tools()\n",
    "\n",
    "# 生成策略数据\n",
    "\n",
    "#趋势类\n",
    "UDVD_results,_= strategies_instance.UDVD()\n",
    "V_MACD_results,_ = strategies_instance.V_MACD()\n",
    "SMA_H_results,_=strategies_instance.SMA_H()\n",
    "\n",
    "#期权类\n",
    "PCR_results,_=strategies_instance.PCR()\n",
    "\n",
    "#宏观类\n",
    "Inventory_Cycle_results,_=strategies_instance.Inventory_Cycle()\n",
    "\n",
    "#情绪类\n",
    "high_low_results,_=strategies_instance.high_low()\n",
    "UD_reults,_=strategies_instance.UD()\n",
    "\n",
    "#外资类\n",
    "FS_A50_results,_=strategies_instance.FS_A50()\n",
    "\n",
    "# 定义添加信号的数据类\n",
    "Adding_Signal = PandasDataPlusSignal\n",
    "\n",
    "# 定义策略和资金分配比例\n",
    "strategies_list = [\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation': 0.0945, 'name': 'UDVD', 'datas': UDVD_results},\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation':0.101, 'name': 'SMA_H', 'datas': SMA_H_results},\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation':0.0864, 'name': 'V_MACD', 'datas': V_MACD_results},\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation':0.1507, 'name': 'UD', 'datas': UD_reults},\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation':0.1816, 'name': 'PCR', 'datas': PCR_results},\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation':0.07816, 'name': 'Inventory_Cycle', 'datas': Inventory_Cycle_results},\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation':0.2076, 'name': 'high_low', 'datas': high_low_results},\n",
    "    {'strategy': EqualWeightsStrategy, 'allocation':0.10, 'name': 'FS_A50', 'datas': FS_A50_results}\n",
    "    ]\n",
    "\n",
    "# 运行组合回测\n",
    "pf_nv, debug_df = tools.Portfolio(strategies_list)\n",
    "\n",
    "# 获取组合净值\n",
    "Portfolio_nv = pf_nv[['Combined']]\n",
    "\n",
    "\n",
    "#组合分析\n",
    "\n",
    "AT=Analyzing_Tools()\n",
    "\n",
    "index_price_path=strategies_instance.paths['daily']\n",
    "\n",
    "portfolio_value, returns, drawdown_ts, metrics = AT.performance_analysis(Portfolio_nv, freq='D')\n",
    "\n",
    "AT.plot_results('000906.SH',index_price_path,Portfolio_nv, drawdown_ts, returns, metrics)\n",
    "\n",
    "Corr=tools.Strategies_Corr_and_NV(pf_nv)\n",
    "\n",
    "tools.set_clusters(Corr,5)\n",
    "\n",
    "\n",
    "#信号处理和目标仓位生成\n",
    "\n",
    "T0_Date='2024-12-27'\n",
    "\n",
    "target_assets_position,difference=tools.caculate_signals_and_trades(debug_df,T0_Date)\n",
    "\n",
    "\n",
    "#所有子策略表现输出\n",
    "\n",
    "export_path=r'D:\\量化交易构建\\私募基金研究\\股票策略研究\\Time_Series_Backtesting\\组合模型\\子策略净值'\n",
    "\n",
    "# pf_nv.to_excel(export_path+'\\\\'+'风险平价组合.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-201\n",
      "登录失败\n"
     ]
    }
   ],
   "source": [
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from analyzing_tools import Analyzing_Tools\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from iFinDPy import *\n",
    "\n",
    "def thslogindemo():\n",
    "    # 输入用户的帐号和密码\n",
    "    thsLogin = THS_iFinDLogin(\"hwqh100\",\"155d50\")\n",
    "    print(thsLogin)\n",
    "    if thsLogin != 0:\n",
    "        print('登录失败')\n",
    "    else:\n",
    "        print('登录成功')\n",
    "\n",
    "thslogindemo()\n",
    "\n",
    "\n",
    "# 定义自定义数据类\n",
    "class PandasDataPlusSignal(bt.feeds.PandasData):\n",
    "    lines = ('signal',)\n",
    "    params = (\n",
    "        ('datetime', None),\n",
    "        ('open', 'open'),\n",
    "        ('high', 'high'),\n",
    "        ('low', 'low'),\n",
    "        ('close', 'close'),\n",
    "        ('volume', 'volume'),\n",
    "        ('openinterest', -1),\n",
    "        ('signal', 'signal'),\n",
    "    )\n",
    "\n",
    "\n",
    "class EqualWeightsStrategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('size_pct',0.19),  # 每个资产的仓位百分比\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.orders = {}         # 用于跟踪每个资产的订单状态\n",
    "        self.trade_counts = {}   # 记录每个资产的交易次数\n",
    "        self.value = []          # 存储组合总净值\n",
    "        self.dates = []          # 存储日期序列\n",
    "        self.debug_info = []     # 存储调试信息\n",
    "\n",
    "        for data in self.datas:\n",
    "            name = data._name\n",
    "            self.trade_counts[name] = 0\n",
    "            self.orders[name] = None\n",
    "\n",
    "    def next(self):\n",
    "        total_value = self.broker.getvalue()\n",
    "        self.value.append(total_value)\n",
    "        current_date = self.datas[0].datetime.datetime(0)\n",
    "        self.dates.append(current_date)\n",
    "\n",
    "        # 调试打印\n",
    "        print(f\"Date: {current_date}, Total Value: {total_value}\")\n",
    "\n",
    "        for data in self.datas:\n",
    "            name = data._name\n",
    "            position_size = self.getposition(data).size\n",
    "            signal = data.signal[0]\n",
    "\n",
    "            # 调试打印\n",
    "            print(f\"Asset: {name}, Position Size: {position_size}, Signal: {signal}\")\n",
    "\n",
    "            # 根据信号执行交易\n",
    "            if signal == 1 and position_size == 0:\n",
    "                size = self.calculate_position_size(data)\n",
    "                self.orders[name] = self.buy(data=data, size=size)\n",
    "                self.trade_counts[name] += 1\n",
    "\n",
    "            elif signal == -1 and position_size > 0:\n",
    "                self.orders[name] = self.close(data=data)\n",
    "                self.trade_counts[name] += 1\n",
    "\n",
    "            # 存储调试信息\n",
    "            self.debug_info.append({\n",
    "                'Date': current_date,\n",
    "                'Asset': name,\n",
    "                'Position': position_size,\n",
    "                'Signal': signal,\n",
    "                'Size': self.calculate_position_size(data),\n",
    "                'Open':data.open[0],\n",
    "                'High':data.high[0],\n",
    "                'Low':data.low[0],\n",
    "                'Volume':data.volume[0],\n",
    "                'Close': data.close[0],\n",
    "                'Cash': self.broker.getcash(),\n",
    "                'Value': total_value,\n",
    "                'Trades': self.trade_counts[name],\n",
    "            })\n",
    "\n",
    "    def calculate_position_size(self, data):\n",
    "        \"\"\"\n",
    "        计算仓位大小\n",
    "        \"\"\"\n",
    "        available_cash = self.broker.getvalue()\n",
    "        current_price = data.close[0]\n",
    "        max_investment = available_cash * self.params.size_pct\n",
    "        max_shares = int(max_investment / current_price)\n",
    "        return max_shares\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        \"\"\"\n",
    "        订单完成后重置状态\n",
    "        \"\"\"\n",
    "        if order.status in [order.Completed, order.Canceled, order.Margin]:\n",
    "            name = order.data._name\n",
    "            self.orders[name] = None\n",
    "\n",
    "    def get_net_value_series(self):\n",
    "        \"\"\"\n",
    "        返回净值序列，用于后续分析\n",
    "        \"\"\"\n",
    "        return pd.Series(self.value, index=self.dates, name='Net Value')\n",
    "\n",
    "    def get_debug_df(self):\n",
    "        \"\"\"\n",
    "        返回包含调试信息的DataFrame\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.debug_info)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        return df\n",
    "\n",
    "#定义组合分析工具类，设置策略起始时间\n",
    "class Tools:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.Begin_Date='2019-01-04'\n",
    "\n",
    "        self.current_position={'000300.SH':51823.20,\n",
    "                \"000852.SH\":32038.40,\n",
    "                '000905.SH':31977.60,\n",
    "                \"399006.SZ\":51647.90,\n",
    "                '399303.SZ':31654.00,\n",
    "                'cash':800538.1}\n",
    "\n",
    "        self.ETF_code={'000300.SH':'510310.SH',\n",
    "                \"000852.SH\":\"159845.SZ\",\n",
    "                '000905.SH':\"512500.SH\",\n",
    "                \"399006.SZ\":\"159915.SZ\",\n",
    "                '399303.SZ':\"159628.SZ\"}       \n",
    "        \n",
    "    def Portfolio(self,strategies,initial_cash=10000000):\n",
    "        Begin_Date=self.Begin_Date\n",
    "        # 创建策略名称到资金分配比例的映射\n",
    "        allocation_map = {strat['name']: strat['allocation'] for strat in strategies}\n",
    "\n",
    "        # 初始化结果存储\n",
    "        strategy_returns = {}\n",
    "        strategy_values = {}\n",
    "        strategy_debug_info = {}\n",
    "        initial_cash = initial_cash  # 总初始资金\n",
    "\n",
    "        # 运行每个策略的回测\n",
    "        for strat in strategies:\n",
    "            cerebro = bt.Cerebro()\n",
    "            # 为该策略设置初始资金\n",
    "            strat_cash = initial_cash * strat['allocation']\n",
    "            cerebro.broker.setcash(strat_cash)\n",
    "            # 添加数据到 Cerebro\n",
    "            for code, dataframe in strat['datas'].items():\n",
    "                # 调试打印数据的前几行\n",
    "                print(f\"Adding data for {code} in strategy {strat['name']}:\")\n",
    "                print(dataframe.head())\n",
    "                # 检查必要的列是否存在\n",
    "                required_columns = ['open', 'high', 'low', 'close', 'volume', 'signal']\n",
    "                if not all(col in dataframe.columns for col in required_columns):\n",
    "                    print(f\"Error: Data for {code} is missing required columns.\")\n",
    "                    continue  # 跳过该数据\n",
    "\n",
    "                dataframe = dataframe.sort_index()\n",
    "                select_dataframe=dataframe.loc[Begin_Date:,:]\n",
    "                data_feed = Adding_Signal(dataname=select_dataframe, name=code)\n",
    "                cerebro.adddata(data_feed)\n",
    "            # 添加策略\n",
    "            cerebro.addstrategy(strat['strategy'])\n",
    "            # 运行回测\n",
    "            result = cerebro.run()\n",
    "            # 获取策略实例\n",
    "            strat_instance = result[0]\n",
    "            # 获取净值序列\n",
    "            net_value = strat_instance.get_net_value_series()\n",
    "\n",
    "            # 调试打印\n",
    "            print(f\"Strategy: {strat['name']}, Net Value Series Length: {len(net_value)}\")\n",
    "            print(net_value.head())\n",
    "\n",
    "            # 检查 net_value 是否为空\n",
    "            if net_value.empty:\n",
    "                print(f\"Warning: Strategy {strat['name']} generated an empty net value series.\")\n",
    "\n",
    "            # 存储净值序列\n",
    "            strategy_values[strat['name']] = net_value\n",
    "            # 收集调试信息\n",
    "            debug_df = strat_instance.get_debug_df()\n",
    "            strategy_debug_info[strat['name']] = debug_df\n",
    "\n",
    "        # 合并净值序列，处理不同数据长度问题\n",
    "        # 获取所有日期的并集\n",
    "        all_dates = pd.to_datetime(sorted(set.union(*(set(v.index) for v in strategy_values.values()))))\n",
    "\n",
    "        # 重新索引净值序列，并填充缺失值\n",
    "        for name, net_value in strategy_values.items():\n",
    "            # 去除重复的日期索引\n",
    "            net_value = net_value[~net_value.index.duplicated(keep='first')]\n",
    "            # 重新索引到所有日期\n",
    "            net_value = net_value.reindex(all_dates)\n",
    "            # 填充缺失值，前向填充\n",
    "            net_value = net_value.fillna(method='ffill')\n",
    "            # 填充初始缺失值为初始资金\n",
    "            initial_net_value = initial_cash * allocation_map[name]\n",
    "            net_value = net_value.fillna(initial_net_value)\n",
    "            strategy_values[name] = net_value\n",
    "\n",
    "        # 将净值序列合并为DataFrame\n",
    "        df_values = pd.DataFrame(strategy_values)\n",
    "        # 计算组合净值曲线\n",
    "        df_values['Combined'] = df_values.sum(axis=1)\n",
    "\n",
    "        # 收集所有子策略的调试信息\n",
    "        combined_debug_df = pd.concat(strategy_debug_info.values(), keys=strategy_debug_info.keys())\n",
    "        combined_debug_df = combined_debug_df.reset_index(level=0).rename(columns={'level_0': 'Strategy'})\n",
    "\n",
    "        return df_values,combined_debug_df\n",
    "\n",
    "    def Strategies_Corr_and_NV(self,pf_nv):\n",
    "        \"\"\"\n",
    "        计算基金多个策略的相关性，并绘制热力图。\n",
    "\n",
    "        参数:\n",
    "            pf_nv (pd.DataFrame): 基金策略的净值数据，行是时间，列是策略名称。\n",
    "\n",
    "        返回:\n",
    "            corr_matrix (pd.DataFrame): 策略的相关性矩阵。\n",
    "        \"\"\"\n",
    "        # 计算净值的每日收益率（百分比变化）\n",
    "        pf_nv_pct_change = pf_nv.pct_change().dropna()\n",
    "\n",
    "        # 计算相关性矩阵\n",
    "        corr_matrix = pf_nv_pct_change.corr()\n",
    "\n",
    "        # 设置绘图风格\n",
    "        sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "        # 绘制热力图\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True)\n",
    "        plt.title(\"Strategies Correlation Heatmap\", fontsize=16)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return corr_matrix\n",
    "\n",
    "    def caculate_signals_and_trades(self,debug_df,T0_Date):\n",
    "\n",
    "        current_position=self.current_position\n",
    "        ETF_code=self.ETF_code\n",
    "        T0_debug=debug_df.loc[T0_Date,:]\n",
    "\n",
    "        #先把signal列的信号转换为0方便计算\n",
    "\n",
    "        T0_debug.loc[T0_debug['Signal']==-1,'Signal']=0\n",
    "\n",
    "        #计算应该下单的调整的size\n",
    "\n",
    "        adjusted_signal_and_size=T0_debug[['Asset','Signal','Size','Close']]\n",
    "        adjusted_signal_and_size.loc[:,\"adjusted_size\"]=adjusted_signal_and_size.loc[:,\"Signal\"]*adjusted_signal_and_size.loc[:,\"Size\"]\n",
    "        adjusted_signal_and_size.loc[:,\"trade_amount\"]=adjusted_signal_and_size.loc[:,\"adjusted_size\"]*adjusted_signal_and_size.loc[:,\"Close\"]\n",
    "        Amount_List= adjusted_signal_and_size.groupby(\"Asset\")[\"trade_amount\"].sum().reset_index()\n",
    "\n",
    "        #提取当日总组合的价值\n",
    "\n",
    "        strategy_value=T0_debug.groupby(\"Strategy\")[\"Value\"].sum().reset_index()\n",
    "        number_of_assets= len(T0_debug['Asset'].unique())\n",
    "        strategy_value.loc[:,\"Value\"]=strategy_value.loc[:,\"Value\"]/number_of_assets\n",
    "        portfolio_value_sum=strategy_value.loc[:,\"Value\"].sum()\n",
    "        \n",
    "        #计算占比\n",
    "        pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "        Amount_List.loc[:,\"portfolio_value\"]=portfolio_value_sum\n",
    "        Amount_List=Amount_List.set_index('Asset',drop=True)\n",
    "        cash_trade_amount=portfolio_value_sum-Amount_List.loc[:,\"trade_amount\"].sum()\n",
    "        cash_row = pd.DataFrame({\n",
    "            'trade_amount': [cash_trade_amount],\n",
    "            'portfolio_value': portfolio_value_sum\n",
    "        }, index=['cash'])\n",
    "        Amount_result=pd.concat([Amount_List,cash_row],axis=0)\n",
    "        Amount_result.loc[:,\"proportion\"]=Amount_result.loc[:,\"trade_amount\"]/Amount_result.loc[:,\"portfolio_value\"]\n",
    "        \n",
    "\n",
    "        #和现有持仓进行对比\n",
    "\n",
    "        current_position_df=pd.DataFrame.from_dict(current_position, orient='index', columns=['current_position_value'])\n",
    "        # 计算 current_position_value 的总和\n",
    "        total_value = current_position_df['current_position_value'].sum()\n",
    "\n",
    "        # 添加占比列\n",
    "        current_position_df['current_position_ratio'] = (\n",
    "            current_position_df['current_position_value'] / total_value\n",
    "        )\n",
    "\n",
    "        #合并现有持仓和目标持仓表\n",
    "\n",
    "        result=pd.merge(Amount_result,current_position_df,right_index=True,left_index=True)\n",
    "        result.loc[:,\"adjusted_position\"]=result.loc[:,\"proportion\"]-result.loc[:,\"current_position_ratio\"]\n",
    "        result.loc[:,\"adjusted_value\"]=total_value*result.loc[:,\"adjusted_position\"]\n",
    "\n",
    "\n",
    "        #根据昨日收盘价计算调仓\n",
    "        \n",
    "        index_code=result.index.to_list()\n",
    "        index_code_list=index_code[:-1]\n",
    "        etf_close_price=[]\n",
    "        for code in index_code_list:\n",
    "            etf=ETF_code[code]\n",
    "            close=THS_HQ(etf,'close','',T0_Date,T0_Date).data\n",
    "            close_price=close[\"close\"].values[0]\n",
    "            etf_close_price.append(close_price)\n",
    "        etf_close_price.append(0)\n",
    "        result.loc[:,\"etf_close_price\"]=etf_close_price\n",
    "        result.loc[:,\"adjusted_shares\"]=result.loc[:,\"adjusted_value\"]/result.loc[:,\"etf_close_price\"]\n",
    "        \n",
    "        #和昨日的信号精选对比\n",
    "\n",
    "        T0_Date_datetime=pd.Timestamp(T0_Date)\n",
    "        unique_dates =debug_df.index.unique()\n",
    "        target_index =unique_dates.get_loc(T0_Date_datetime)\n",
    "        if target_index > 0:\n",
    "            previous_date = unique_dates[target_index - 1]\n",
    "\n",
    "        previous_date_df=debug_df.loc[previous_date,:]\n",
    "\n",
    "        #抽取信号信息和表弟信息\n",
    "        previous_date_signal=previous_date_df[['Asset',\"Strategy\",'Signal']]\n",
    "        previous_date_signal=previous_date_signal.reset_index(drop=True)\n",
    "        yesterday_result = previous_date_signal.pivot(index='Asset', columns='Strategy', values='Signal')\n",
    "        \n",
    "        T0_debug_signal=debug_df.loc[T0_Date,:]\n",
    "\n",
    "        T0_debug_signal=T0_debug_signal[['Asset',\"Strategy\",'Signal']]\n",
    "        T0_debug_signal=T0_debug_signal.reset_index(drop=True)\n",
    "        T0_result = T0_debug_signal.pivot(index='Asset', columns='Strategy', values='Signal')\n",
    "        \n",
    "        comparison = T0_result == yesterday_result\n",
    "\n",
    "        if not comparison.values.all():  # 如果存在 False\n",
    "            print(\"信号改变\")\n",
    "        else:\n",
    "            print(\"信号没有改变\")\n",
    "\n",
    "        result=result[['trade_amount','proportion','current_position_ratio','adjusted_position','adjusted_value',\n",
    "                        'etf_close_price','adjusted_shares']]\n",
    "        \n",
    "        return result,comparison\n",
    "    \n",
    "    def set_clusters(self,Corr_df,n_groups):\n",
    "        # 假设 Corr_df 是已经计算好的相关性矩阵\n",
    "        # 转换相关性为距离\n",
    "        distance_matrix = 1 - Corr_df\n",
    "\n",
    "        # 执行层次聚类\n",
    "        linked = linkage(distance_matrix, 'average')\n",
    "\n",
    "        # 绘制树状图来观察聚类情况\n",
    "        dendrogram(linked, labels=Corr_df.index)\n",
    "        plt.title('Dendrogram')\n",
    "        plt.xlabel('Strategy Index')\n",
    "        plt.ylabel('Distance')\n",
    "        # plt.axhline(y=1.4, color='r', linestyle='--')  # 添加一条红线表示截断位置\n",
    "        plt.show()\n",
    "\n",
    "        # # 根据树状图选择的截断值进行聚类\n",
    "        # clusters = fcluster(linked, 1.4, criterion='distance')\n",
    "\n",
    "        # 直接指定生成三个聚类\n",
    "        clusters = fcluster(linked, n_groups, criterion='maxclust')\n",
    "\n",
    "        # 将聚类结果添加到原始 DataFrame 中\n",
    "        Corr_df['Cluster'] = clusters\n",
    "\n",
    "        # 输出聚类结果\n",
    "        print(Corr_df['Cluster'])\n",
    "\n",
    "        # 创建一个字典来存储每个聚类的成员列表\n",
    "        cluster_dict = {}\n",
    "        for cluster_id in np.unique(clusters):\n",
    "            cluster_dict[cluster_id] = list(Corr_df.index[Corr_df['Cluster'] == cluster_id])\n",
    "\n",
    "        # 输出每个聚类的成员\n",
    "        for key, value in cluster_dict.items():\n",
    "            print(f\"Cluster {key}: {value}\")\n",
    "\n",
    "        return cluster_dict\n",
    "\n",
    "\n",
    "# 定义策略类（设置数据路径和选择资产）\n",
    "class Strategies:\n",
    "\n",
    "    def __init__(self):\n",
    "        # 定义数据路径\n",
    "        self.paths = {\n",
    "            'daily': r'D:\\数据库\\同花顺ETF跟踪指数量价数据\\1d',\n",
    "            'hourly': r'D:\\数据库\\同花顺ETF跟踪指数量价数据\\1h',\n",
    "            'min15': r'D:\\数据库\\同花顺ETF跟踪指数量价数据\\15min',\n",
    "            'option': r'D:\\数据库\\另类数据\\ETF期权数据',\n",
    "            'EDB':r'D:\\数据库\\同花顺EDB数据',\n",
    "            'new_HL': r'D:\\数据库\\另类数据\\新高新低\\001005010.csv',\n",
    "            'up_companies':r'D:\\数据库\\另类数据\\涨跌家数\\A股.csv',\n",
    "            'up_down': r'D:\\数据库\\另类数据\\涨停跌停\\001005010.csv',\n",
    "            'A50': r'D:\\数据库\\另类数据\\A50数据\\CN0Y.SG.csv',\n",
    "            #'pv_export':r\"D:\\量化交易构建\\私募基金研究\\股票策略研究\\策略净值序列\"\n",
    "        }\n",
    "        # 定义选择的资产\n",
    "        self.target_assets = [\"000300.SH\",\"000852.SH\",\n",
    "                              \"000905.SH\", \"399006.SZ\",\"399303.SZ\"]\n",
    "\n",
    "    # 突破类策略\n",
    "    def UDVD(self,window_1=27):\n",
    "        # 信号结果字典\n",
    "        results = {}\n",
    "        # 全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "\n",
    "        paths=self.paths\n",
    "\n",
    "        # 编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            df=daily_data.copy()\n",
    "            close = df[\"close\"]\n",
    "            open = df['open']    \n",
    "            low = df[\"low\"]\n",
    "            high = df[\"high\"]\n",
    "            volume = df['volume']\n",
    "            # 计算\n",
    "            volup = (high-open)/open\n",
    "            voldown = (open-low)/open\n",
    "            ud= volup - voldown\n",
    "\n",
    "            df[\"var_1\"] = ud.rolling(window_1).mean()\n",
    "            df[\"var_2\"] =0\n",
    "            # 添加信号列\n",
    "            df.loc[(df[\"var_1\"].shift(1) <= df[\"var_2\"].shift(1)) & (df[\"var_1\"] >= df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) > df[\"var_2\"].shift(1)) & (df[\"var_1\"] < df[\"var_2\"]) , 'signal'] = -1\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "            result=df\n",
    "\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    #均线类策略\n",
    "    def Alligator_strategy_with_Ao_and_Fractal_Macd(self):\n",
    "        # 信号结果字典\n",
    "        results = {}\n",
    "        # 全数据字典，包含计算指标用于检查\n",
    "        full_info = {}\n",
    "\n",
    "        paths=self.paths\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            hourly_data = pd.read_csv(os.path.join(paths['hourly'], f\"{code}.csv\"), index_col=[0])\n",
    "            hourly_data.index = pd.to_datetime(hourly_data.index)\n",
    "            mins_15_data = pd.read_csv(os.path.join(paths['min15'], f\"{code}.csv\"), index_col=[0])\n",
    "            mins_15_data.index = pd.to_datetime(mins_15_data.index)\n",
    "            mins_15_data = mins_15_data[~mins_15_data.index.duplicated(keep='first')]\n",
    "\n",
    "            # 提取收盘价\n",
    "            daily_data_close = daily_data[['close']]\n",
    "            daily_data_high = daily_data[['high']]\n",
    "            daily_data_low = daily_data[['low']]\n",
    "            hourly_data_close = hourly_data[['close']]\n",
    "            mins_15_data_close = mins_15_data[['close']]\n",
    "\n",
    "            # 确保数据为数值类型\n",
    "            daily_data_high = pd.to_numeric(daily_data_high.squeeze(), errors='coerce')\n",
    "            daily_data_low = pd.to_numeric(daily_data_low.squeeze(), errors='coerce')\n",
    "\n",
    "            # 计算鳄鱼线指标\n",
    "            Jaw = daily_data_close.rolling(window=13).mean().shift(8)\n",
    "            Jaw.columns=['Jaw']\n",
    "            Teeth = hourly_data_close.rolling(window=8).mean().shift(5)\n",
    "            Teeth.columns=['Teeth']\n",
    "            Lips = mins_15_data_close.rolling(window=5).mean().shift(3)\n",
    "            Lips.columns=['Lips']\n",
    "\n",
    "            # 合并鳄鱼线数据并统一到日频\n",
    "            combined = pd.concat([daily_data, Jaw, Teeth, Lips], axis=1)\n",
    "            combined.fillna(method='ffill', inplace=True)\n",
    "            result = combined.resample('D').last()\n",
    "            result.dropna(inplace=True)\n",
    "\n",
    "            # 生成交易信号\n",
    "            def signal_generation(row):\n",
    "                if row['Lips'] > row['Teeth'] > row['Jaw']:\n",
    "                    return 1  # 多头信号\n",
    "                elif row['Lips'] < row['Teeth'] < row['Jaw']:\n",
    "                    return -1  # 空头信号\n",
    "                else:\n",
    "                    return 0  # 无信号\n",
    "\n",
    "            result['Alligator_signal'] = result.apply(signal_generation, axis=1)\n",
    "\n",
    "            #分形形态信号计算\n",
    "            def identify_fractals_and_record_values(df):\n",
    "                \"\"\"\n",
    "                识别分形并记录过去 5 日的最高价的最高值和最低价的最低值。\n",
    "                :param data: 包含时间序列数据的 DataFrame，需包含 'high', 'low', 'close' 列。\n",
    "                :return: 包含 up_fractal_value 和 down_fractal_value 的 DataFrame。\n",
    "                \"\"\"\n",
    "                # 初始化两列用于记录分形值\n",
    "                data=df.copy()\n",
    "                data['up_fractal_value'] = None\n",
    "                data['down_fractal_value'] = None\n",
    "\n",
    "                # 遍历数据，识别分形并记录关键值\n",
    "                for i in range(4, len(data) - 4):  # 确保有足够的数据进行完整分形判断\n",
    "                    # 向上分形：中间高点最高，且左右两侧逐级降低\n",
    "                    if (data['high'][i] > data['high'][i - 1] and data['high'][i] > data['high'][i + 1] and  # 中间点高于左右\n",
    "                        data['high'][i - 1] > data['high'][i - 2] and data['high'][i + 1] > data['high'][i + 2] and  # 左右点高于更远点\n",
    "                        data['high'][i - 2] > data['high'][i - 3] and data['high'][i + 2] > data['high'][i + 3]):  # 更远点高于最远点\n",
    "                        # 记录过去 5 日的最高价的最高值\n",
    "                        data.loc[data.index[i], 'up_fractal_value'] = data['high'][i - 4:i + 1].max()\n",
    "\n",
    "                    # 向下分形：中间低点最低，且左右两侧逐级升高\n",
    "                    if (data['low'][i] < data['low'][i - 1] and data['low'][i] < data['low'][i + 1] and  # 中间点低于左右\n",
    "                        data['low'][i - 1] < data['low'][i - 2] and data['low'][i + 1] < data['low'][i + 2] and  # 左右点低于更远点\n",
    "                        data['low'][i - 2] < data['low'][i - 3] and data['low'][i + 2] < data['low'][i + 3]):  # 更远点低于最远点\n",
    "                        # 记录过去 5 日的最低价的最低值\n",
    "                        data.loc[data.index[i], 'down_fractal_value'] = data['low'][i - 4:i + 1].min()\n",
    "\n",
    "                # 向下填充分形值\n",
    "                data['up_fractal_value'].fillna(method='ffill', inplace=True)\n",
    "                data['down_fractal_value'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "                return data\n",
    "            \n",
    "            def calculate_fractal_signals(df):\n",
    "                \"\"\"\n",
    "                基于分形值计算交易信号，并在特定情况下保持上一周期的信号。\n",
    "                :param data: 包含 'close', 'up_fractal_value', 'down_fractal_value' 列的 DataFrame。\n",
    "                :return: 包含 fractal_signal 的 DataFrame。\n",
    "                \"\"\"\n",
    "                # 初始化信号列，默认值为 0\n",
    "                data=df.copy()\n",
    "                data['fractal_signal'] = 0\n",
    "\n",
    "                # 遍历数据，每一行根据条件更新信号\n",
    "                for i in range(1, len(data)):\n",
    "                    if data['close'][i] > data['up_fractal_value'][i]:  # 收盘价高于最近的上分形的最高价，看多\n",
    "                        data.loc[data.index[i], 'fractal_signal'] = 1\n",
    "                    elif data['close'][i] < data['down_fractal_value'][i]:  # 收盘价低于最近的下分形的最低价，看空\n",
    "                        data.loc[data.index[i], 'fractal_signal'] = -1\n",
    "                    else:  # 其他情况，维持上一周期的信号\n",
    "                        data.loc[data.index[i], 'fractal_signal'] = 0\n",
    "\n",
    "                return data\n",
    "    \n",
    "            fractals_data= identify_fractals_and_record_values(daily_data)\n",
    "            fractals_signals = calculate_fractal_signals(fractals_data)\n",
    "            result['Fractal_signal'] = fractals_signals['fractal_signal']\n",
    "\n",
    "            # 计算 AO 指标\n",
    "            median_price = (daily_data_high + daily_data_low) / 2\n",
    "            ao_short = median_price.rolling(window=5).mean()\n",
    "            ao_long = median_price.rolling(window=34).mean()\n",
    "            AO = ao_short - ao_long\n",
    "\n",
    "            # 将 AO 转化为 DataFrame，并与鳄鱼线数据对齐\n",
    "            ao_df = AO.to_frame(name='AO').dropna()  # 将 AO 转换为 DataFrame\n",
    "\n",
    "            # 计算 AO 的变化方向\n",
    "            ao_df['AO_Diff'] = ao_df['AO'].diff()\n",
    "\n",
    "            # 判断连续上涨和下跌天数\n",
    "            ao_df['Up_Count'] = (ao_df['AO_Diff'] > 0).astype(int).rolling(window=3).sum()\n",
    "            ao_df['Down_Count'] = (ao_df['AO_Diff'] < 0).astype(int).rolling(window=3).sum()\n",
    "\n",
    "            # 根据规则生成信号\n",
    "            ao_df['AO_signal'] = np.where(ao_df['Up_Count'] == 3, 1, \n",
    "                                        np.where(ao_df['Down_Count'] == 3, -1, np.nan))\n",
    "\n",
    "            # 延续上一个信号\n",
    "            ao_df['AO_signal'] = ao_df['AO_signal'].fillna(0)\n",
    "\n",
    "            # 删除辅助列，保留 AO 和 AO_signal\n",
    "            ao_df = ao_df[['AO_signal']]\n",
    "\n",
    "            result=pd.merge(result,ao_df,right_index=True,left_index=True)\n",
    "\n",
    "            #计算MACD指标\n",
    "            df = daily_data.copy()\n",
    "            # 1. 计算快线（DIFF）和慢线（DEA）\n",
    "            df['ema_short'] = df['close'].ewm(span=12, adjust=False).mean()\n",
    "            df['ema_long'] = df['close'].ewm(span=26, adjust=False).mean()\n",
    "            df['diff'] = df['ema_short'] - df['ema_long']  # DIFF 快线\n",
    "            df['dea'] = df['diff'].ewm(span=9, adjust=False).mean()  # DEA 慢线\n",
    "            \n",
    "            # 2. 计算能量柱\n",
    "            df['macd_bar'] = (df['diff'] - df['dea']) * 2\n",
    "\n",
    "            # 添加macd信号列\n",
    "            def macd_generate_signal(row):\n",
    "                # 水上或零轴看多信号\n",
    "                if row['diff'] > row['dea'] and row['macd_bar'] >= 0:\n",
    "                    return 1\n",
    "                # 水下或零轴看空信号\n",
    "                elif row['diff'] < row['dea'] and row['macd_bar'] <= 0:\n",
    "                    return -1\n",
    "                # 无信号\n",
    "                else:\n",
    "                    return 0\n",
    "\n",
    "            # 应用macd信号生成规则\n",
    "            df['MACD_signal'] = df.apply(macd_generate_signal, axis=1)\n",
    "            \n",
    "            macd_df=df[['MACD_signal']]\n",
    "\n",
    "            result=pd.merge(result,macd_df,right_index=True,left_index=True)\n",
    "            #计算最终信号\n",
    "\n",
    "            result['signal'] = 0\n",
    "            for i in range(len(result)):\n",
    "                long_condition = (result['Alligator_signal'][i] == 1 and \n",
    "                                (result['MACD_signal'][i] == 1 or result['Fractal_signal'][i] == 1\n",
    "                                or result['AO_signal'][i] == 1)\n",
    "                                )\n",
    "                short_condition = (result['Alligator_signal'][i] == -1 or\n",
    "                                result['AO_signal'][i] == -1 or result['Fractal_signal'][i] == -1 or\n",
    "                                result['MACD_signal'][i]== -1)\n",
    "                \n",
    "                if long_condition and short_condition:  # 同时触发多空信号\n",
    "                    result['signal'][i] = result['signal'][i - 1] if i > 0 else 0  # 延续上一周期信号\n",
    "                elif long_condition:\n",
    "                    result['signal'][i] = 1  # 看多\n",
    "                elif short_condition:\n",
    "                    result['signal'][i] = -1  # 看空\n",
    "                else:\n",
    "                    result['signal'][i] = result['signal'][i - 1] if i > 0 else 0 # 延续上一周期信号\n",
    "\n",
    "            # 存储结果\n",
    "            signal=result[['signal']]\n",
    "            results[code]=pd.merge(daily_data,signal,right_index=True,left_index=True)\n",
    "            full_info[code] = result  # 包含所有信号计算信息的数据\n",
    "\n",
    "        return results, full_info\n",
    "\n",
    "        # 自定义数据类，包含 'signal'\n",
    "        class PandasDataPlusSignal(bt.feeds.PandasData):\n",
    "            lines = ('signal',)\n",
    "            params = (\n",
    "                ('signal', -1),  # 默认情况下，'signal' 列在最后一列   \n",
    "            )\n",
    "\n",
    "    def SMA_H(self,window_1=61,window_2=101):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        \n",
    "        paths=self.paths\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "\n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            df=daily_data.copy()\n",
    "            hourly_data = pd.read_csv(os.path.join(paths['hourly'], f\"{code}.csv\"), index_col=[0])\n",
    "            hourly_data.index = pd.to_datetime(hourly_data.index)\n",
    "\n",
    "            hourly_data[\"var_1\"] = hourly_data['close'].rolling(window_1).mean()\n",
    "            hourly_data[\"var_2\"] =hourly_data['close'].rolling(window_2).mean()\n",
    "            # 添加信号列\n",
    "            hourly_data.loc[(hourly_data[\"var_1\"].shift(1) <= hourly_data[\"var_2\"].shift(1)) & (hourly_data[\"var_1\"] >= hourly_data[\"var_2\"]) , 'signal'] = 1\n",
    "            hourly_data.loc[(hourly_data[\"var_1\"].shift(1) > hourly_data[\"var_2\"].shift(1)) & (hourly_data[\"var_1\"] < hourly_data[\"var_2\"]) , 'signal'] = -1\n",
    "            \n",
    "            hourly_data['signal'].fillna(method='ffill', inplace=True)\n",
    "            hourly_exchange = hourly_data.resample('D').last()\n",
    "\n",
    "            df = pd.merge(df, hourly_exchange[['signal']], left_index=True, right_index=True, how='left')        \n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "            result=df\n",
    "\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    # 成交量类策略\n",
    "    def V_MACD(self,window_1=42,window_2=0):\n",
    "        # 信号结果字典\n",
    "        results = {}\n",
    "        # 全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "\n",
    "        paths=self.paths\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "        \n",
    "        # 编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "\n",
    "            volume = df['volume']\n",
    "            df['EMA_F'] =volume.ewm(12).mean()\n",
    "            df['EMA_S'] = volume.ewm(26).mean()\n",
    "            df['V_DIF'] = df['EMA_F'] - df['EMA_S']\n",
    "            df['V_DEA'] = df['V_DIF'].ewm(9).mean()\n",
    "            df['VMACD']=(df['V_DIF']-df['V_DEA'])*2\n",
    "\n",
    "            # 标准化处理\n",
    "            df['VMACD_mean'] = df['VMACD'].rolling(window_1).mean()\n",
    "            df['VMACD_std'] = df['VMACD'].rolling(window_1).std()\n",
    "            df['Z_VMACD'] = (df['VMACD'] - df['VMACD_mean']) / df['VMACD_std']\n",
    "            df['VMACD_MTM'] = df['Z_VMACD'].rolling(window_1).sum()\n",
    "\n",
    "            # 计算\n",
    "            df[\"var_1\"] = df['VMACD_MTM']\n",
    "            df[\"var_2\"] = window_2/10\n",
    "            df[\"var_3\"] = -window_2/10\n",
    "\n",
    "            # 信号触发条件\n",
    "            df.loc[(df[\"var_1\"].shift(1) <= df[\"var_2\"].shift(1)) & (df[\"var_1\"] > df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) > df[\"var_3\"].shift(1)) & (df[\"var_1\"] <= df[\"var_3\"]), 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    #期权类策略\n",
    "    def PCR(self,window_1=62):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "            option_code='510050'\n",
    "            data = pd.read_csv(os.path.join(paths['option'], f\"{option_code}.csv\"), index_col=[0])\n",
    "            data.index= pd.to_datetime(data.index)\n",
    "            \n",
    "            #和指数数据合并\n",
    "            merged_df = pd.merge(df, data[['p02872_f005', 'p02872_f006']], left_index=True, right_index=True, how='left')        \n",
    "            #计算PCR滚动五天的均值\n",
    "            merged_df['PCR']= merged_df['p02872_f006'].rolling(5).mean()/merged_df['p02872_f005'].rolling(5).mean()\n",
    "            # 定义一个函数来计算从小到大排列后排名第 70% 的值\n",
    "            def calc_70th_percentile(x):\n",
    "                return np.percentile(x, 70)\n",
    "\n",
    "            # 使用 rolling 方法计算过去六十日从小到大排列后第 70 个百分位数\n",
    "            merged_df['rolloing_70%'] = merged_df['PCR'].rolling(window_1).apply(calc_70th_percentile, raw=True)\n",
    "\n",
    "            df['PCR'] = merged_df['PCR']\n",
    "            df['rolloing_70%'] = merged_df['rolloing_70%']\n",
    "\n",
    "\n",
    "            # 信号触发条件\n",
    "            df.loc[(df[\"PCR\"].shift(1) <= df[\"rolloing_70%\"].shift(1)) & (df[\"PCR\"] > df[\"rolloing_70%\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"PCR\"].shift(1) > df[\"rolloing_70%\"].shift(1)) & (df[\"PCR\"] <= df[\"rolloing_70%\"]), 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "    #宏观类策略\n",
    "\n",
    "    def Inventory_Cycle(self,window_1=7):\n",
    "        #PMI：原材料库存代码=M002043811\n",
    "        #BCI:企业库存前瞻指数=M004488064 \n",
    "\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        \n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据量价数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "            df=daily_data.copy()\n",
    "\n",
    "            #读取EDB数据\n",
    "            PMI_Inventory= pd.read_csv(paths['EDB']+'\\\\'+'M002043811.csv')\n",
    "            PMI_Inventory=PMI_Inventory.set_index('time',drop=True)\n",
    "            PMI_Inventory_value=PMI_Inventory[['value']]\n",
    "            PMI_Inventory_value.columns=['PMI_Inventory_Index']\n",
    "            PMI_Inventory_value=PMI_Inventory_value.sort_index()\n",
    "            #计算第一个信号（PMI原材料库存信号）\n",
    "\n",
    "            def process_macro_data_rolling(data, column_name, window=36):\n",
    "                \"\"\"\n",
    "                对输入的宏观数据进行滚动极端值处理和Zscore标准化处理（基于滚动窗口）。\n",
    "\n",
    "                参数：\n",
    "                data : pd.DataFrame\n",
    "                    包含待处理数据的DataFrame。\n",
    "                column_name : str\n",
    "                    需要处理的列名。\n",
    "                window : int\n",
    "                    滚动窗口的大小（默认为36列）。\n",
    "                \n",
    "                返回：\n",
    "                pd.DataFrame\n",
    "                    包含处理后数据的DataFrame，新增列为 {column_name}_Zscore。\n",
    "                \"\"\"\n",
    "                # 确保列存在\n",
    "                if column_name not in data.columns:\n",
    "                    raise ValueError(f\"列名 {column_name} 不存在于输入数据中\")\n",
    "\n",
    "                # 初始化新列\n",
    "                zscore_column_name = f\"{column_name}_Zscore\"\n",
    "                data[zscore_column_name] = np.nan\n",
    "\n",
    "                # 滚动窗口计算\n",
    "                for i in range(window - 1, len(data)):\n",
    "                    # 提取过去window列的数据\n",
    "                    rolling_window = data[column_name].iloc[i - window + 1:i + 1]\n",
    "\n",
    "                    # 计算滚动均值和标准差\n",
    "                    mean = rolling_window.mean()\n",
    "                    std = rolling_window.std()\n",
    "\n",
    "                    # 定义上下限\n",
    "                    upper_limit = mean + 3 * std\n",
    "                    lower_limit = mean - 3 * std\n",
    "\n",
    "                    # 当前值进行极端值处理\n",
    "                    current_value = data[column_name].iloc[i]\n",
    "                    clipped_value = np.clip(current_value, lower_limit, upper_limit)\n",
    "\n",
    "                    # 计算Zscore并赋值\n",
    "                    data.loc[data.index[i], zscore_column_name] = (clipped_value - mean) / std\n",
    "                    data.dropna()\n",
    "\n",
    "                return data[['PMI_Inventory_Index_Zscore']]\n",
    "            \n",
    "            PMI_Inventory_Index_Zscore=process_macro_data_rolling(PMI_Inventory_value,'PMI_Inventory_Index')\n",
    "            #输出PMI的信号\n",
    "            multiplier=window_1/10\n",
    "        \n",
    "            def generate_signals_with_cleaning(data, column_name, window=36, multiplier=0.8):\n",
    "                \"\"\"\n",
    "                根据Zscore生成信号，并删除前36个月的数据以避免回测时出错\n",
    "\n",
    "                参数：\n",
    "                data : pd.DataFrame\n",
    "                    包含处理后数据的DataFrame\n",
    "                column_name : str\n",
    "                    需要处理的列名（Zscore列）\n",
    "                window : int, 可选\n",
    "                    滚动窗口大小，默认为36个月\n",
    "                multiplier : float, 可选\n",
    "                    标准差的倍数，默认为0.8\n",
    "\n",
    "                返回：\n",
    "                pd.DataFrame\n",
    "                    包含信号的DataFrame，删除了前36个月的数据\n",
    "                \"\"\"\n",
    "                if column_name not in data.columns:\n",
    "                    raise ValueError(f\"列名 {column_name} 不存在于输入数据中\")\n",
    "\n",
    "                # 计算滚动标准差\n",
    "                rolling_std = data[column_name].rolling(window=window).std()\n",
    "\n",
    "                # 计算正负0.8倍标准差\n",
    "                upper_bound = multiplier * rolling_std\n",
    "                lower_bound = -multiplier * rolling_std\n",
    "\n",
    "                # 初始化信号\n",
    "                signals = []\n",
    "\n",
    "                # 生成信号\n",
    "                for i in range(len(data)):\n",
    "                    if i < window:  # 在滚动窗口大小之前，无数据可用\n",
    "                        signals.append(np.nan)\n",
    "                    else:\n",
    "                        if data[column_name].iloc[i] > upper_bound.iloc[i]:\n",
    "                            signals.append(-1)  # 看空信号\n",
    "                        elif data[column_name].iloc[i] < lower_bound.iloc[i]:\n",
    "                            signals.append(1)  # 看多信号\n",
    "                        else:\n",
    "                            signals.append(signals[-1])  # 维持上一个信号\n",
    "\n",
    "                # 将信号加入数据框\n",
    "                data['Signal'] = signals\n",
    "\n",
    "                # 删除前36个月的数据（滚动窗口前的数据）\n",
    "                data = data.iloc[window:].copy()\n",
    "\n",
    "                return data[['Signal']]\n",
    "                    \n",
    "            PMI_Signals = generate_signals_with_cleaning(PMI_Inventory_Index_Zscore, 'PMI_Inventory_Index_Zscore',multiplier=multiplier)\n",
    "\n",
    "            PMI_Signals.columns=['signal']\n",
    "\n",
    "            PMI_Signals.index=pd.to_datetime(PMI_Signals.index)\n",
    "\n",
    "            # 使用 resample 将月频转换为日频\n",
    "            PMI_Signals_daily = PMI_Signals.resample('D').ffill()\n",
    "            PMI_Signals_daily.index=pd.to_datetime(PMI_Signals_daily.index)\n",
    "            \n",
    "            #存储结果\n",
    "            total_info=pd.concat([daily_data,PMI_Signals_daily],axis=1)\n",
    "            first_signal_date=PMI_Signals_daily.index[0]\n",
    "            first_signal_formatted_date=first_signal_date.strftime('%Y-%m-%d')\n",
    "            total_info_selected=total_info.loc[first_signal_formatted_date:,:]\n",
    "\n",
    "            #填充缺失值\n",
    "            total_info_selected=total_info_selected.ffill()\n",
    "\n",
    "            signal=total_info_selected[['signal']]\n",
    "\n",
    "            daily_data.loc[:,\"signal\"]=signal\n",
    "\n",
    "            results[code] = daily_data.dropna()\n",
    "\n",
    "            full_info[code]=daily_data    \n",
    "        \n",
    "        return results,full_info\n",
    "\n",
    "    #情绪类\n",
    "\n",
    "    def high_low(self,window_1=12):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        \n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "\n",
    "            #将上涨、平、下跌数量和涨跌停数量合并\n",
    "            high_low_path=paths['new_HL']\n",
    "            high_low=pd.read_csv(high_low_path)\n",
    "            up_company_path=paths['up_companies']\n",
    "            data = pd.read_csv(up_company_path)\n",
    "            data=data.rename(columns={'p00112_f001':'time'})\n",
    "            high_low['time'] = pd.to_datetime(high_low['time'])\n",
    "            data['time'] = pd.to_datetime(data['time'])\n",
    "            num_df = pd.merge(high_low, data[['p00112_f002', 'p00112_f003', 'p00112_f004', 'time']], on='time', how='left')        \n",
    "            num_df.set_index('time', inplace=True)\n",
    "\n",
    "            #和指数数据合并\n",
    "            merged_df = pd.merge(df, num_df[['ths_new_high_num_block','ths_new_low_num_block','p00112_f002', 'p00112_f003', 'p00112_f004']], left_index=True, right_index=True, how='left')        \n",
    "            \n",
    "            #计算涨跌停剪刀差\n",
    "            merged_df['股票数量']=merged_df['p00112_f002'] +  merged_df['p00112_f003'] + merged_df['p00112_f004']\n",
    "            merged_df['新高数量']=merged_df['ths_new_high_num_block']\n",
    "            merged_df['新低数量']=merged_df['ths_new_low_num_block']\n",
    "            merged_df['高低差']=(merged_df['新高数量']-merged_df['新低数量'])/merged_df['股票数量']\n",
    "            merged_df['高低差'].fillna(method='ffill', inplace=True)\n",
    "            # 确保merged_df的索引唯一\n",
    "            merged_df = merged_df[~merged_df.index.duplicated(keep='first')]\n",
    "\n",
    "            df['var_1'] = merged_df['高低差']\n",
    "            df['var_2'] = -0.2\n",
    "            df['var_3']=window_1/1000\n",
    "            # 根据条件生成信号值列\n",
    "            df.loc[(df[\"var_1\"].shift(1) >= df[\"var_2\"].shift(1)) & (df[\"var_1\"] < df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) < df[\"var_3\"].shift(1)) & (df[\"var_1\"] >= df[\"var_3\"]) , 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n",
    "\n",
    "    def UD(self,window_1=38,window_2=65):\n",
    "            #信号结果字典\n",
    "            results = {}\n",
    "            #全数据字典，包含计算指标用于检查\n",
    "            full_info={}\n",
    "            target_assets=self.target_assets\n",
    "            paths=self.paths\n",
    "            \n",
    "            #编写策略主体部分\n",
    "            for code in target_assets:\n",
    "                # 读取数据\n",
    "                daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "                daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "                df=daily_data.copy()\n",
    "\n",
    "                #将上涨、平、下跌数量和涨跌停数量合并\n",
    "                up_down_path=paths['up_down']\n",
    "                up_down=pd.read_csv(up_down_path)\n",
    "                up_company_path=paths['up_companies']\n",
    "                data = pd.read_csv(up_company_path)\n",
    "                data=data.rename(columns={'p00112_f001':'time'})\n",
    "                up_down['time'] = pd.to_datetime(up_down['time'])\n",
    "                data['time'] = pd.to_datetime(data['time'])\n",
    "                num_df = pd.merge(up_down, data[['p00112_f002', 'p00112_f003', 'p00112_f004', 'time']], on='time', how='left')        \n",
    "                num_df.set_index('time', inplace=True)\n",
    "\n",
    "                #和指数数据合并\n",
    "                merged_df = pd.merge(df, num_df[['ths_limit_up_stock_num_sector','ths_limit_down_stock_num_sector','p00112_f002', 'p00112_f003', 'p00112_f004']], left_index=True, right_index=True, how='left')        \n",
    "                \n",
    "                #计算涨跌停剪刀差\n",
    "                merged_df['股票数量']=merged_df['p00112_f002'] +  merged_df['p00112_f003'] + merged_df['p00112_f004']\n",
    "                merged_df['涨停数量']=merged_df['ths_limit_up_stock_num_sector']\n",
    "                merged_df['跌停数量']=merged_df['ths_limit_down_stock_num_sector']\n",
    "                merged_df['涨跌停差']=(merged_df['涨停数量']-merged_df['跌停数量'])/merged_df['股票数量']\n",
    "\n",
    "                # 计算AMA\n",
    "                merged_df['AMA_30'] = merged_df['涨跌停差'].ewm(window_1).mean()\n",
    "                merged_df['AMA_100'] = merged_df['涨跌停差'].ewm(window_2).mean()\n",
    "                merged_df['AMA']=merged_df['AMA_30']/merged_df['AMA_100']\n",
    "\n",
    "\n",
    "                merged_df['ration']=merged_df['AMA']\n",
    "                # 确保merged_df的索引唯一\n",
    "                merged_df = merged_df[~merged_df.index.duplicated(keep='first')]\n",
    "\n",
    "                df['var_1'] = merged_df['ration']\n",
    "                df['var_2'] = 1.15\n",
    "                df['var_3']=merged_df['AMA_30']\n",
    "                df['var_4']=merged_df['AMA_100']\n",
    "\n",
    "                # 根据条件生成信号值列\n",
    "                df['signal_1'] = -1  # 初始化信号列为 -1\n",
    "                condition = (df['var_1'] > df['var_2']) & (df['var_3'] > 0) & (df['var_4'] > 0)\n",
    "                df.loc[condition, 'signal_1'] = 1\n",
    "                \n",
    "                df['var_5'] = merged_df['涨跌停差']\n",
    "                df['var_6'] = -0.2\n",
    "                df['var_7']=0.019\n",
    "                # 根据条件生成信号值列\n",
    "                df.loc[(df[\"var_5\"].shift(1) >= df[\"var_6\"].shift(1)) & (df[\"var_5\"] < df[\"var_6\"]) , 'signal_2'] = 1\n",
    "                df.loc[(df[\"var_5\"].shift(1) < df[\"var_7\"].shift(1)) & (df[\"var_5\"] >= df[\"var_7\"]) , 'signal_2'] = -1\n",
    "                # pos为空的，向上填充数字\n",
    "                df['signal_2'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "                df['signal_sum']=df['signal_1']+df['signal_2']\n",
    "                # 添加signal列，使用apply函数\n",
    "                df['signal'] = df['signal_sum'].apply(lambda x: 1 if x >= 0 else -1)\n",
    "                result=df\n",
    "                # 将信号合并回每日数据\n",
    "                daily_data = daily_data.join(result[['signal']], how='left')\n",
    "                daily_data[['signal']].fillna(0, inplace=True)\n",
    "                daily_data=daily_data.dropna()\n",
    "\n",
    "                # 存储结果\n",
    "                results[code] = daily_data\n",
    "                full_info[code]=result\n",
    "\n",
    "            return results,full_info\n",
    "\n",
    "    #外资类\n",
    "    \n",
    "    def FS_A50(self,window_1=20):\n",
    "        #信号结果字典\n",
    "        results = {}\n",
    "        #全数据字典，包含计算指标用于检查\n",
    "        full_info={}\n",
    "        target_assets=self.target_assets\n",
    "        paths=self.paths\n",
    "        \n",
    "        #编写策略主体部分\n",
    "        for code in target_assets:\n",
    "            # 读取数据\n",
    "            daily_data = pd.read_csv(os.path.join(paths['daily'], f\"{code}.csv\"), index_col=[0])\n",
    "            daily_data.index = pd.to_datetime(daily_data.index)\n",
    "\n",
    "            df=daily_data.copy()\n",
    "            df = df.round(0)\n",
    "            # 使用需要的列，通常是高、低、收盘价\n",
    "            close = df[\"close\"]    \n",
    "            low = df[\"low\"]\n",
    "            open= df['open']\n",
    "            high = df[\"high\"]\n",
    "            volume = df['volume']\n",
    "\n",
    "            #导入富时A50\n",
    "            A50_Path=paths['A50']\n",
    "            data = pd.read_csv(A50_Path)\n",
    "            #导入中证全指\n",
    "            zzqz=pd.read_csv(os.path.join(paths['daily'], f\"{'000985.CSI'}.csv\"))\n",
    "            #日期\n",
    "            data['time'] = pd.to_datetime(data['time'])\n",
    "            zzqz['time'] = pd.to_datetime(zzqz['time'])\n",
    "            #self.df['time'] = pd.to_datetime(self.df['time'])\n",
    "            #按照时间升序排列\n",
    "            data= data.sort_values(by='time')\n",
    "            zzqz= zzqz.sort_values(by='time')\n",
    "            #计算涨跌幅\n",
    "            data['chg']=(data['ths_close_price_future']-data['ths_open_price_future'])/data['ths_open_price_future']\n",
    "            merged_df = pd.merge(zzqz, data[['time', 'chg']], left_on='time', right_on='time', how='left')\n",
    "            # 向下填充'value'列的NaN值\n",
    "            merged_df['chg'].fillna(method='ffill', inplace=True)\n",
    "            #计算富时A50及中证全指差值\n",
    "            merged_df['diff']=merged_df['chg']-(merged_df['close']-merged_df['open'])/merged_df['open']\n",
    "            #将中证全债及富时A50的差合并到df中\n",
    "            merged_df.set_index('time', inplace=True)   \n",
    "\n",
    "            df = pd.merge(df, merged_df[['diff']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "\n",
    "            df['var_1'] = df['diff']\n",
    "            df['var_2'] = window_1/1000\n",
    "            \n",
    "            df.loc[(df[\"var_1\"].shift(1) <= df[\"var_2\"].shift(1)) & (df[\"var_1\"] > df[\"var_2\"]) , 'signal'] = 1\n",
    "            df.loc[(df[\"var_1\"].shift(1) > df[\"var_2\"].shift(1)) & (df[\"var_1\"] <= df[\"var_2\"]) , 'signal'] = -1\n",
    "\n",
    "            # pos为空的，向上填充数字\n",
    "            df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            result=df\n",
    "            # 将信号合并回每日数据\n",
    "            daily_data = daily_data.join(result[['signal']], how='left')\n",
    "            daily_data[['signal']].fillna(0, inplace=True)\n",
    "            daily_data=daily_data.dropna()\n",
    "\n",
    "            # 存储结果\n",
    "            results[code] = daily_data\n",
    "            full_info[code]=result\n",
    "\n",
    "        return results,full_info\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
